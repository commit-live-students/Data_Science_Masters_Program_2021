{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "***\n",
    "\n",
    "## Description: You will learn about the much widely used Logistic Regression, why it is used for classification and its real world applications. \n",
    "\n",
    "***\n",
    "\n",
    "## Overview\n",
    "- Why not Linear Regression for classification\n",
    "- Sigmoid function\n",
    "- Cost function with gradient descent\n",
    "- Evaluation metrics\n",
    "\n",
    "***\n",
    "\n",
    "## Pre-requisite\n",
    "- Python\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Statistics\n",
    "- Probability\n",
    "- Differential Calculus\n",
    "- Linear Regression\n",
    "\n",
    "***\n",
    "\n",
    "## Learning Objective\n",
    "- Understand when to use Logistic Regression\n",
    "- Usage of odds, odds ratio and sigmoid function\n",
    "- Binary and multi-class classification\n",
    "- Different evaluation metrics for classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Why not Linear Regression for classification?\n",
    "\n",
    "***\n",
    "\n",
    "## Description: Understand what is classification and why Linear Regression is not a good algorithm to handle such a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What is classification?\n",
    "\n",
    "***\n",
    "\n",
    "Classification is a central topic in machine learning that has to do with teaching machines how to group together data by particular criteria. It is different from regression in the sense that target variables in classification are discrete in nature while in regression they are continuous. Remember that both regression and classification fall into the category of supervised learning approaches.\n",
    "\n",
    "There is an also an unsupervised version of classification, called clustering where computers find shared characteristics by which to group data when categories are not specified (we will encounter it later, not in this concept).\n",
    "\n",
    "**Examples**\n",
    "\n",
    "<img src='../images/example.jpg' >\n",
    "\n",
    "Other common examples of classification come with classifying loan defaulters, predicting patients as having diabetes or not etc. \n",
    "\n",
    "All these types of classification problems can be effectively solved by Logistic Regression. Even though it contains the word \"regression\", do not take it as a regression algorithm. It is a linear model for classification and is widely used both in academia and industry mainly due to its simplicity and interpretibility. \n",
    "\n",
    "\n",
    "**What is the difference between linear regression and logistic regression?**\n",
    "\n",
    "- *Outcome*: This is the fundamental and possibly the most intuitive difference between both the algorithms. In linear regression, the outcome (dependent variable) is continuous. It can have any one of an infinite number of possible values, for instance, weight, height, number of hours, etc. Whereas in logistic regression, the outcome (dependent variable) has only a limited number of possible values. For instance, yes/no, true/false, red/green/blue, 1st/2nd/3rd/4th, etc.\n",
    "\n",
    "\n",
    "- *Linear regression output as probabilities*: Its tempting to use the linear regression output as probabilities but it's a mistake because the output can be negative, and greater than 1 whereas probability can not. As regression might actually produce probabilities that could be less than 0, or even bigger than 1, logistic regression was introduced.\n",
    "\n",
    "- *Equation*: Linear regression has its own equation of the form: $y = \\theta_0 + \\theta_1x_1 + ...+ \\theta_nx_n$. Logistic regression has a somewhat different equation as it interprets probability. You will learn more about it in the coming chapters where its equation is given by $ y = \\frac{1}{1+e^{-(\\theta_0 + \\theta_1x_1 + ...+ \\theta_nx_n)}}$\n",
    "\n",
    "\n",
    "\n",
    "*NOTE*: **Although there is regression at the end of its name Logistic Regression is used for classification purposes. At the same time it is a form of linear model only since the logistic function is a linear combination of weights (you will see later on in this course).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Introduction to the dataset\n",
    "\n",
    "***\n",
    "\n",
    "Throughout the entire concept we will be using the Banknote authentication dataset where you will be classifying bank notes as **Authentic** or **Fake** based on given information.  The data was extracted from images that were taken for the evaluation of an authentication procedure for banknotes. There are 5 attributes in total in this dataset and a brief description about them is given below:\n",
    "\n",
    "1. `variance`: variance of Wavelet Transformed image (**continuous**) \n",
    "2. `skewness`: skewness of Wavelet Transformed image (**continuous**) \n",
    "3. `curtosis`: curtosis of Wavelet Transformed image (**continuous**) \n",
    "4. `entropy`: entropy of image (**continuous**) \n",
    "5. `class`: authentic($1$) or fake($0$) (**integer**) \n",
    "\n",
    "\n",
    "The datasets consists of four predictor variables (`variance`, `skewness`, `curtosis` and `entropy`) and a target variable, `class`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now lets load the dataset and look at the characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Load the dataset and print out its shape and total number of missing values.\n",
    "\n",
    "### Instructions\n",
    "- Load the dataset with the argument `bank.csv` using pandas `.read_csv()` method\n",
    "- Print out the shape using `.shape` method\n",
    "- Print out the total number of missing values using the `.isnull().sum()` method of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 5)\n",
      "variance    0\n",
      "skewness    0\n",
      "curtosis    0\n",
      "entropy     0\n",
      "class       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = '../data/data.csv'\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# display shape\n",
    "print(data.shape)\n",
    "\n",
    "# count of missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Load data as `data = pd.read_csv(file_path)`\n",
    "- Visualize shape as `data.shape`\n",
    "- Count of missing values as `data.isnull().sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- variable declaration of `data`\n",
    "- Shape of `data`: `data.shape == (1372, 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Solving with linear regression\n",
    "\n",
    "***\n",
    "\n",
    "In the last concept you learnt about Linear Regression. Lets try to solve this problem with Linear Regression first. \n",
    "\n",
    "At first, lets take only the feature `entropy` to predict the `class` from it. We will look at how the decision boundary looks like and how will the line behave with an useen data point. **In worst case scenario the unseen point can be an outlier. We want our model to generalize well and so, we will test for the worst case scenario.**\n",
    "\n",
    "The code snippet is given below:\n",
    "```python\n",
    "# import packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# instantiate model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "linear_model.fit(df[['entropy']], df[['class']])\n",
    "\n",
    "# generate 1000 X-values\n",
    "X_sample = np.linspace(-9, 3, 1000)\n",
    "\n",
    "# calculate y-values for 1000 X-values\n",
    "Y_sample = X_sample*linear_model.intercept_ + linear_model.coef_[0]\n",
    "\n",
    "# threshold for entropy\n",
    "threshold  = (0.5 - linear_model.coef_[0]) / linear_model.intercept_\n",
    "print(threshold)\n",
    "\n",
    "# scatter plot \n",
    "plt.scatter(df[['entropy']], df[['class']], marker='x')\n",
    "\n",
    "# axes specifications\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Class {1:Authentic, 0:Fake}')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "\n",
    "# threshold lines\n",
    "plt.axvline(threshold, linestyle='--', color='green')\n",
    "plt.axhline(0.5, linestyle='--', color='black')\n",
    "\n",
    "# line plot\n",
    "plt.plot(X_sample, Y_sample, color='red')\n",
    "\n",
    "# display plot\n",
    "plt.show()\n",
    "```\n",
    "We get the output as:\n",
    "\n",
    "```python\n",
    "Threshold value is: [0.47315246]\n",
    "```\n",
    "And the output image looks somewhat like this:\n",
    "\n",
    "<img src='../images/1.png'>\n",
    "\n",
    "\n",
    "**Context of the code snippet**\n",
    "- Trained a linear regression model `linear_model` on `entropy` and `class`\n",
    "- Used `linear_model` to predict on 1000 samples (`X_sample`)\n",
    "- Black horizontal line is the `class` threshold (set to 0.5 in our setting)\n",
    "- Green vertical line is the corrseponding threshold for `entropy`\n",
    "- Red line is the decision boundary\n",
    "\n",
    "\n",
    "Lets understand more on decision boundary now.\n",
    "\n",
    "**Decision boundary**: It is a sort of demarcation or criteria based on which we segregate our data into different groups. In the image below the straight line is a decision boundary separating the two sets points colored red and blue. We can also have non-linear decision boundaries (you will learn in the next chapter about it) as well as higher dimensional ones.\n",
    "\n",
    "<img src='../images/db.png'>\n",
    "\n",
    "In our setting `class` attribute has values either $0$ or $1$. Since we have fit a line, we assume that for y-value above $0.5$, we consider it as `1` and `0` for values lower than $0.5$. The threshold value is the value for `entropy` at which the `class` changes; which according to our code is approximately 0.47."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Linear Regression for Classification? Not a good idea\n",
    "\n",
    "***\n",
    "\n",
    "You saw that the threshold value for `entropy` was around $0.47$. Upon addition of a new data point we want the threshold values for `entropy` to change as little as possible so that it isn't affected by outliers. Lets add an outlier point and observe for ourselves whether or not the decison boundary and threshold changes.\n",
    "\n",
    "The code snippet is given for you:\n",
    "\n",
    "```python\n",
    "# instantiate linear model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# add outlier pointd to 'entropy' and 'class'\n",
    "x = np.append(df.entropy.values, [35]).reshape(-1,1)\n",
    "y = np.append(df['class'], [1]).reshape(-1,1)\n",
    "\n",
    "# fit on new 'entropy' and 'class'\n",
    "lm.fit(x, y)\n",
    "\n",
    "# scatter plot \n",
    "plt.scatter(x, y, marker='x')\n",
    "\n",
    "# axes modification\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Class {1:Authentic, 0:Fake}')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "\n",
    "# new threshold\n",
    "new_threshold = (0.5 - lm.coef_[0]) / lm.intercept_\n",
    "\n",
    "# threshold lines\n",
    "plt.axvline(new_threshold, linestyle='--', color='green')\n",
    "plt.axhline(0.5, linestyle='--', color='black')\n",
    "plt.axvline(threshold, linestyle='--', color='yellow')\n",
    "\n",
    "# line plots\n",
    "new_Y_sample = X_sample*lm.intercept_ + lm.coef_[0]\n",
    "plt.plot(X_sample, new_Y_sample, color='red')\n",
    "plt.xlim(-8, 3)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The image looks somewhat like this: <img src='../images/2.png'>\n",
    "\n",
    "**From the image it is pretty clear that the threshold value changes as evident from the line changing its color from yellow to green**. As the threshold changes, so does the predictions and so linear regression is not a reliable model for this type of tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. Is Logistic Regression used for regression?\n",
    "\n",
    "    a. TRUE\n",
    "\n",
    "    b. FALSE\n",
    " \n",
    "**Ans:** b. FALSE, don't get mislead by the use of the term \"regression\".\n",
    "\n",
    "\n",
    "2. Using Linear regression for classification tasks results in the line being sensitive to outliers?\n",
    "\n",
    "    a. TRUE\n",
    "\n",
    "    b. FALSE\n",
    " \n",
    "**Ans:** a. TRUE, see the example above as well as the video if you got this one incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Nuts and bolts of Logistic Regression\n",
    "\n",
    "***\n",
    "\n",
    "## Description: In this chapter you will learn about sigmoid function, odds ratio and cost function for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sigmoid function\n",
    "\n",
    "***\n",
    "\n",
    "As you have seen at the end of the previous chapter, Linear Regression is not suitable for classification tasks mainly due to a couple of reasons:\n",
    "- Upon addition of outliers, the best-fit line changes which in turn changes the threshold for the decision boundary. \n",
    "- Linear combination of features $\\theta_0 + \\sum_{i=1}^{n}\\theta_ix_i$ spans from $-\\infty \\text{ to } \\infty$. But for a classification (binary) one you can have only two possible values (for example: $0 \\text{ and } 1$)\n",
    "\n",
    "*Hence, linear regression is a very unstable process for classification tasks*.  \n",
    "\n",
    "\n",
    "**Cure for classification problems** \n",
    "\n",
    "We can overcome it with the help of the **`sigmoid`** function, also known as the S-curve. It looks somewhat like this: <img src='../images/sigmoid.png'> \n",
    "\n",
    "In the figure we consider negative labels as having the value $0$ while the positive ones as being $1$s. \n",
    "\n",
    "***`Mathematical Form and Interpretation`***         \n",
    "\n",
    "$ \\sigma(z) = \\frac {1} {(1 + e^(-z))}$ where $z = \\theta_0 + \\theta_1x + ..... + \\theta_nx$\n",
    "\n",
    "Probabilistically speaking, we have:\n",
    "\n",
    "$ \\begin{align}\n",
    "P(y=1|x) &= h_\\theta(x) = \\frac{1}{1 + \\exp(-\\theta^\\top x)} \\equiv \\sigma(\\theta^\\top x),\\\\\n",
    "P(y=0|x) &= 1 - P(y=1|x) = 1 - h_\\theta(x).\n",
    "\\end{align} $\n",
    "\n",
    "**The sigmoid gives the probability of predicted output being positive against some pre-defined threshold**. For example: If we predict less than $0.5$ we call it negative otherwise we term it positive. Notice the term $z$ which is the same as the hypothesis of linear regression. \n",
    "\n",
    "*Maximum value of sigmoid:* $1$ for $z = \\infty$ \n",
    "\n",
    "*Minimum value of sigmoid:* $0$ for $z = -\\infty$. \n",
    "\n",
    "Thus, sigmoid is perfectly suitable for our binary classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make your own sigmoid function\n",
    "\n",
    "In this task you will be defining a sigmoid function which takes in a single argument and returns the sigmoid output as given in the slide.\n",
    "\n",
    "### Instructions\n",
    "- Define a function `sigmoid` that takes in a single variable x and returns the sigmoid transformation (Use `np.exp()` to represent exponent)\n",
    "- Calculate the `sigmoid` value for $0$ and save it as `result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+(np.exp(-x)))\n",
    "\n",
    "result = sigmoid(0)\n",
    "print(result)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Function `sigmoid` must return $\\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `result`\n",
    "- Function declaration of `sigmoid`\n",
    "- Value of result: `result == 0.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Odds ratio \n",
    "\n",
    "***\n",
    "\n",
    "So by now you know that the sigmoid function gives us the probability of an instance belong to either of the classes. But ever wondered how we arrived at this step? Well, something called the odds-ratio helped us in arriving at the final form $g(z) = \\frac {1} {(1 + e^(-z))}$. So let us understand more about odds ratio now.\n",
    "\n",
    "\n",
    "**What is odds ratio?**\n",
    "\n",
    "We will answer this question with the help of an example. Let the probability of success of an event is p ( $0 <= p <= 1$ ). So, the probability of event failure is 1 - p. The ratio of probability of success to probability of failure is called the odds ratio. Mathematically, it is equivalent to $ \\frac{p}{1-p} $. If some event has odds of 4, then it means that the chances of success are 4 times more likely than those of failure. \n",
    "\n",
    "An interesting property of odds is that it is a monotonically increasing function. Odds increase as the probability increases or vice versa. \n",
    "\n",
    "<img src='../images/Odd.png'>\n",
    "\n",
    "\n",
    "**Log odds**\n",
    "\n",
    "The transformation from odds to log of odds is the log transformation.  This is also  a monotonic transformation i.e. greater the odds, greater the log of odds and vice versa.  \n",
    "\n",
    "<img src='../images/log.png'>\n",
    "\n",
    "\n",
    "**Why take log odds?**\n",
    "\n",
    "Its difficult to model a variable with probability since it has restricted range between 0 and 1. The log of the odds also called logits transformation is an attempt to get around the restricted range problem. It maps probability ranging between 0 and 1 to log odds ranging from negative infinity to positive infinity. \n",
    "\n",
    "\n",
    "A logistic regression model allows us to establish a relationship between a binary outcome variable and a group of predictor variables.  It models the logit-transformed probability as a linear relationship with the predictor variables. Mathematically,\n",
    "\n",
    "$\\text{logit(p)} = log(\\frac{p}{1-p}) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + .... + \\theta_nx_n$\n",
    "\n",
    "\n",
    "**Observe how the right hand side of the equation looks similar to the linear regression counterpart.**\n",
    "\n",
    "> $ p = \\frac{e^{\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + .... + \\theta_nx_n}}{1 + e^{\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + .... + \\theta_nx_n}}$\n",
    "\n",
    "> $ p = \\frac{1}{1 + e^-({\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + .... + \\theta_nx_n})} $ which is the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Decision boundary for sigmoid function\n",
    "\n",
    "***\n",
    "\n",
    "The mathematical condition for decision boundary in case of sigmoid will occur when the probability is $0.5$.\n",
    "\n",
    "i.e. $y = 0.5$\n",
    "$$ => 1 + e^{-z} = 0.5 $$\n",
    "$$ => e^{-z} = 1 $$\n",
    "$$ =>z = 0 $$\n",
    "$$ => \\theta^TX = 0 $$\n",
    "\n",
    "Now, $\\theta^TX = \\theta_0 + \\theta_1x_1 + .... + \\theta_nx_n$. \n",
    "\n",
    "**So, this condition i.e. $\\theta_0 + \\theta_1x_1 + .... + \\theta_nx_n = 0$ is the equation for the decision boundary of sigmoid function.** \n",
    "\n",
    "By adding polynomial terms to the left hand side of the above equation we can also get a non-linear decision boundary. Lets say you have the function $$h_θ(x) = g(θ_0 + θ_1x_1+ θ_2x_2 + θ_3x_1^2 + θ_4x_2^2)$$.\n",
    "\n",
    "Decision boundary for this equation is $$θ_0 + θ_1x_1+ θ_2x_2 + θ_3x_1^2 + θ_4x_2^2 = 0$$\n",
    "\n",
    "Say θ was $[-1,0,0,1,1]$ then we have; \n",
    "\n",
    "Predict that $y = 1$ if\n",
    " - $-1 + x_1^2 + x_2^2 >= 0$ or\n",
    " - $x_1^2 + x_2^2 >= 1$\n",
    " \n",
    "Else predict $y = 0$\n",
    "\n",
    "The decision boundary for the above example is a circle of radius $1$ and is shown in the image below.\n",
    "\n",
    "<img src='../images/non_linear_db.png'>\n",
    "\n",
    "\n",
    "**Stability of sigmoid functions decision boundary**\n",
    "\n",
    "The main advantage of the sigmoid function is that always buckets values in the range of [0,1] and it does not get affected by outliers at all. Take a look at the code snippet below and the images that it produces:\n",
    "\n",
    "```python\n",
    "# import packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg1 = LogisticRegression()\n",
    "logreg2 = LogisticRegression()\n",
    "\n",
    "# Outlier points added\n",
    "x = np.append(df.entropy.values, [35]).reshape(-1,1)\n",
    "y = np.append(df['class'], [1]).reshape(-1,1)\n",
    "\n",
    "# fit model\n",
    "logreg1.fit(df[['entropy']], df[['class']])\n",
    "logreg2.fit(x, y)\n",
    "\n",
    "# initialize figures\n",
    "fig, (ax_1, ax_2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "# scatter plot\n",
    "ax_1.scatter(df[['entropy']], df[['class']], marker='x')\n",
    "ax_2.scatter(x,y, marker='x')\n",
    "\n",
    "# axes modifications\n",
    "ax_1.set_title('Without outlier')\n",
    "ax_2.set_title('With outlier')\n",
    "ax_1.set_xlabel('Entropy')\n",
    "ax_1.set_ylabel('Class {1:Authentic, 0:Fake}')\n",
    "ax_2.set_xlabel('Entropy')\n",
    "ax_2.set_ylabel('Class {1:Authentic, 0:Fake}')\n",
    "\n",
    "# predictions\n",
    "old_pred = logreg1.predict(X_sample.reshape(-1,1))\n",
    "new_pred = logreg2.predict(X_sample.reshape(-1,1))\n",
    "\n",
    "# line plots showing decision boundary for sigmoid\n",
    "ax_1.plot(X_sample.reshape(-1,1), old_pred, color='red')\n",
    "ax_2.plot(X_sample.reshape(-1,1), new_pred, color='red')\n",
    "ax_2.set_xlim(-9, 3)\n",
    "\n",
    "# display plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<img src='../images/sig.png'>\n",
    "\n",
    "The decision boundary is robust enough to deal with outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Multiclass Classification\n",
    "\n",
    "***\n",
    "\n",
    "So far we have discussed binary classification only. But what if we have more than two target classes? How to approach such problems? For this kind of situations we will be covering two methods; namely One-vs-All (One-vs-Rest) method and the Softmax method. Lets discuss them in details.\n",
    "\n",
    "1. *__One-vs-all Method__*\n",
    "\n",
    "   Consider the situation where you have K classes ( $ K > 2 $ ). You will create classifiers equal to the number of classes and use each of them to predict one class as 1 and other classes as 0s. Then you combine all the classifiers and obtain a single new classifier which assigns probabilities to instances belonging to every class. On encountering a new instance, it will output probability of that instance belonging to every class and in general we select it as the highest of the predicted probabilities. But like all other methods, this approach is also not bullet-proof. Particularly in problems with class imbalance it doesn't have the desired effect.\n",
    "   \n",
    "   For example you have a situation at hand to classify shapes as triangles, squares and crosses. So for this classification problem you will make 3 logistic classifiers. The first classifier will classify triangles as 1s and the other classes as 0s. Similarly the second classifier will classify squares as 1s and other classes as 0s and the third one will classify crosses as 1s and other classes as 0s. We combine these three classifiers and obtain a single classifer which can now classify shapes into any of the three classes. \n",
    "   \n",
    "   <img src='../images/onevsall.png'> \n",
    "   \n",
    "   You can go through scikit-learn's official [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) of One-vs-rest classifier.\n",
    "\n",
    "\n",
    "2. *__Softmax Function__*\n",
    "\n",
    "    Softmax is an extension of sigmoid function generalized for K classes. Consider you have m training examples $(x^{1}, y^{1}), (x^{2}, y^{2}), ..., (x^{n}, y^{n})$ and the class labels as $y^{(i)} \\in \\{1, 2, \\ldots, K\\}$. \n",
    "    \n",
    "    Now, given a new input $x$ we want to predict the probability that it belongs each of the classes i.e. $P(y=k | x)$. The hypothesis is given by the equation:\n",
    "    \n",
    "   $ \\begin{align}\n",
    "h_\\theta(x) =\n",
    "\\begin{bmatrix}\n",
    "P(y = 1 | x; \\theta) \\\\\n",
    "P(y = 2 | x; \\theta) \\\\\n",
    "\\vdots \\\\\n",
    "P(y = K | x; \\theta)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\frac{1}{ \\sum_{j=1}^{K}{\\exp(\\theta^{(j)\\top} x) }}\n",
    "\\begin{bmatrix}\n",
    "e^{\\theta^{1}\\top} x  \\\\\n",
    "e^{\\theta^{2}\\top} x  \\\\\n",
    "\\vdots \\\\\n",
    "e^{\\theta^{K}\\top} x ) \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align} $\n",
    "\n",
    "    The hypothesis outputs a $ K $ dimensional vector whose elements sum to 1 giving us our $ K $ estimated probabilities. Here, $\\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{(K)} \\in \\Re^{n}$ are the model parameters. \n",
    "    \n",
    "    Every $\\theta^{(i)}$ is again made up of $ n $ parameters and so it is convenient $ \\theta $ as a $ n\\text{x}K $ matrix where $\\theta = \\left[\\begin{array}{cccc}| & | & | & | \\\\\n",
    "\\theta^{(1)} & \\theta^{(2)} & \\cdots & \\theta^{(K)} \\\\\n",
    "| & | & | & |\n",
    "\\end{array}\\right].$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. In logistic regression, what do we estimate for one each unit’s change in X?\n",
    "\n",
    "    a. Change in Y multiplied with Y\n",
    "    \n",
    "    b. Change in Y from mean\n",
    "    \n",
    "    c. How much Y changes\n",
    "    \n",
    "    d. How much the natural logarithm of the odds for Y = 1 changes\n",
    "\n",
    "    **Ans:** d. It represents for each unit change in X how much the natural logarithm of the odds for Y = 1 changes\n",
    "\n",
    "\n",
    "2. A total predicted logit of 0 can be transformed to a probability of?\n",
    "\n",
    "    a. 1\n",
    "    \n",
    "    b. 0\n",
    "    \n",
    "    c. 0.5\n",
    "    \n",
    "    d. 0.25\n",
    "    \n",
    "    **Ans:** c. $log\\frac{p}{1-p} = 0$. Solving it we have $p = 0.5$\n",
    "\n",
    "3. Which of the following option is true?\n",
    "\n",
    "    a. Linear Regression errors values has to be normally distributed but in case of Logistic Regression it is not the case\n",
    "\n",
    "    b. Logistic Regression errors values has to be normally distributed but in case of Linear Regression it is not the case\n",
    "\n",
    "    **Ans:** a. Linear Regression errors values has to be normally distributed but in case of Logistic Regression it is not the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Cost Function\n",
    "\n",
    "***\n",
    "\n",
    "## Description: In this chapter you will learn about the cost function for logistic regression and why is it so. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cost function for Logistic Regression\n",
    "\n",
    "***\n",
    "\n",
    "From the previous tutorial on linear regression, we know that the cost function ($J(\\theta$)) for $m$ training examples with hypothesis $h_\\theta(x_i)$ and actual target $y_i$ is \n",
    "\n",
    "$$ J(\\theta) =   \\frac{1}{m}\\sum_{i=1}^{m}\\frac{1}{2}(h_\\theta(x_i) - y_i)^2$$\n",
    "\n",
    "Now for linear regression, this is a convex cost function i.e. you are guaranteed to arrive at the global minimum cost. However, the same cannot be said for sigmoid function and applying the same for logistic regression where our hypothesis is $h_\\theta(x) = \\frac{1}{1 + e{-\\theta^TX}}$.  It is  a non-convex function and chances are we might get stuck in some local minima while optimizing our solution. \n",
    "\n",
    "It is depicted in the image below where we can see multiple local minimas for a non-convex function. The image is taken from the massively popular lecture notes from Dr. Andrew NG.\n",
    "\n",
    "<img src='../images/convex.png'>\n",
    "\n",
    "\n",
    "**Maximum Likelihood Estimation**\n",
    "\n",
    "In logistic regression instead of minimizing the least squares error, we try to maximize the likelihood. Likelihood function determines how likely is the observation according to the model. It determines values for the model parameters such that they maximise the chance that the process described by the model produced the data that were actually observed.\n",
    "\n",
    "Lets assume our hypothesis to be $ h_\\theta (x) $ with data points $ (x_i, y_i) $ where $ 0 <= h_\\theta (x) <= 1 $. The probability of observing positive class is given by $ h_\\theta (x) $ and that of observing negative class is given by $ 1 - h_\\theta (x) $. \n",
    "\n",
    "Assuming the underlying distribution as Bernoulli, the objective function becomes \n",
    "\n",
    "$$ \\text{Likelihood (L)} = \\prod^{m}_{i=1} h_\\theta (x_i)^{y_i} (1 - h_\\theta (x_i))^{1-y_i}$$\n",
    "\n",
    "Notice that we take products and not the sum while calculating the likelihood as total likelihood is the product of the likelihood of every observation. For convenience, it is easy to deal with the log-form of likelihood. Taking the natural logarithm of the above equation gives us:\n",
    "\n",
    "$$ \\ln(\\text{L}) = \\sum^{m}_{i=1}[y_i \\ln h_\\theta(x_i) + (1 - y_i)\\ln(1 - h_\\theta(x_i))]$$ \n",
    "\n",
    "Maximizing L is the same as minimizing -L and by taking the average over the entire set of m data points we obtain the new cost function as:\n",
    "\n",
    "$$ J(\\theta)  = -\\frac{1}{m}\\sum_{i=1}^{m}[y_i\\ln h_\\theta(x_i) + (1-y_i) \\ln (1-h_\\theta(x_i) )]$$\n",
    "\n",
    "This term is our new cost function. Maximizing the log likelihood will give us an optimal solution as it will result in the maximum likelihood (L) and give us the best parameters. \n",
    "\n",
    "\n",
    "**Gradient Descent to find best parameters**\n",
    "\n",
    "We have the sigmoid function $\\sigma(x) = \\frac{1}{1 + e^{\\theta^T X}}$ \n",
    "\n",
    "On calculating the derivative w.r.t. $ \\theta $ we obtain the best parameters for a single sample:\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} L(\\theta) = -(y \\frac{1}{\\sigma(\\theta^TX)} - (1-y)  \\frac{1}{1 - \\sigma(\\theta^TX)})  \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^TX) $\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} L(\\theta) = -(y \\frac{1}{\\sigma(\\theta^TX)} - (1-y)  \\frac{1}{1 - \\sigma(\\theta^TX)})  \\sigma(\\theta^TX)(1 - \\sigma(\\theta^TX)) \\frac{\\partial}{\\partial \\theta_j} \\theta^TX $\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} L(\\theta) = -(y(1-\\sigma(\\theta^TX)) - (1-y)\\sigma(\\theta^TX))x_j$\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} L(\\theta) = (\\sigma(\\theta^TX)-y)x_j $\n",
    "\n",
    "Adding up over all the samples we obtain:\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{m} \\sum_{i = 1}^m (h_\\theta(x_i)-y_i)x_j$\n",
    "\n",
    "After that we can update the weights ( $\\theta$s ) as per : $\\theta = \\theta + \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Intuition behind the Cost Function\n",
    "\n",
    "***\n",
    "\n",
    "Now lets get into the intuition behind the cost function $J(\\theta)  = -\\frac{1}{m}\\sum_{i=1}^{m}[y_i\\ln h_\\theta(x_i) + (1-y_i) \\ln (1-h_\\theta(x_i) )]$\n",
    "\n",
    "\n",
    "We will be considering two scenarios, one when the actual target is **1** and other when it is **0**. The intuition is explained with the help of the image below where the X-axis represents the predicted values and Y-axis represents the cost $J(\\theta$).\n",
    "\n",
    "**Case I: $y = 1$** \n",
    "\n",
    "The cost function becomes  $ J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m} \\ln h_\\theta(x_i) $, since $ (1 - y_i) = 0$.\n",
    "\n",
    "Its graphical representation is given by the red line in the image below. Carefully observe that if we predict probabilities close to $0$, the cost is almost infinity; but as our prediction reaches $1$, it approaches $0$. \n",
    "Thus, it highly penalizes incorrect predictions.\n",
    "\n",
    "\n",
    "**Case II: $y = 0$**\n",
    "\n",
    "Now, this cost function becomes $ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m}(1 - y_i) \\ln (1 - h_\\theta(x_i))$.\n",
    "\n",
    "This is represented by the black line in the image below. For wrong predictions, it penalizes much more and for closer ones, it penalizes very less. \n",
    "\n",
    "This is the intuition behind cost function for logistic regression. After that the weights are being updated in the same manner as linear regression; the only difference being the cost function $J (\\theta)$.\n",
    "\n",
    "**With regularization, there is just an added term in cost function and accordingly the weights will get updated so that it doesn't overfit.**\n",
    "\n",
    "\n",
    "<img src='../images/loss.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model building using scikit-learn\n",
    "\n",
    "***\n",
    "\n",
    "Till now, you have learnt about classification, sigmoid function and the modifications in the cost function for logistic regression. Now, you will perform necessary preprocessing steps and build a model on that data using **scikit-learn**.\n",
    "\n",
    "**Remember these steps as well as the sequence is not universal, there are various other things to check for.** \n",
    "\n",
    "\n",
    "**Step 1:Split into train and test sets** \n",
    "\n",
    "Split the data into train and test sets with 20% data in the test set\n",
    "\n",
    "\n",
    "**Step 2:Standardize data**\n",
    "\n",
    "Although it is not a mandatory step, since we will be finding co-efficients using gradient descent, it is recommended to use normalization so that it converges faster\n",
    "\n",
    "\n",
    "**Possible other measures:**\n",
    "\n",
    "- **Check for multicollinearity** \n",
    "Logistic regression requires there to be little or no multicollinearity among the independent variables.  This means that the independent variables should not be too highly correlated with each other. If there exists some collinearity, avoid using them together.\n",
    "\n",
    "- **Check for missing values and treat them**\n",
    "\n",
    "\n",
    "In this topic we will be only performing only train-test split and standardize data with zero mean and unit variance.\n",
    "\n",
    "After that you can fit the model on training data and use that to predict on unseen or test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "In this task you are going to split the data into train and test and then standardize the data\n",
    "\n",
    "### Instructions\n",
    "- All the packages have been imported for you\n",
    "- Use `.train_test_split()` to split the dataset into train and test datasets with $20$% test data and `random_state=42`. Name them as `X_train`, `X_test`, `y_train` and `y_test`\n",
    "- Initialize a scaler named `scaler` with `MinMaxScaler`. You can read more about it at [Documentation](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n",
    "- Fit this scaler on the train data using `.fit(X_train)` and then transform both the train and test features with `.transform()` method\n",
    "- Instantiate a Logistic Regression model `model` and fit it on the transformed training features and training target i.e. `X_train` and `y_train`\n",
    "- Then make predictions on the transformed test features i.e. `X_test` and store it as `pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0\n",
      " 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1\n",
      " 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1\n",
      " 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bick23/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:4], data['class'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "pred = model.predict(X_test)\n",
    "print(pred)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `X_train`, `X_test`, `y_train`, `y_test`, `scaler`, `model` and `pred`\n",
    "- Length of `pred`: `len(pred) == 275`\n",
    "- Sum of values in `pred`: `sum(pred) == 117`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Do train-test split as `X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:4], data['class'], test_size=0.2, random_state=42)`\n",
    "- Fit `scaler` on `X_train` as `scaler.fit(X_train)` and then transform as `X_train = scaler.transform(X_train)` and `X_test = scaler.transform(X_test)`\n",
    "- Fit `model` on training data as `model.fit(X_train, y_train)` and predict as `model.predict(X_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Evaluation Metrics for Classification\n",
    "\n",
    "***\n",
    "\n",
    "## Description: In this chapter you will learn more about the different metrics for classification like accuracy score, precision, recall, f-1 score, AUC score etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion matrix\n",
    "\n",
    "***\n",
    "\n",
    "Also called the error matrix, it is a table describing the performance of a supervised machine learning model on the testing data, where the true values are unknown. Each **row of the matrix** represents the instances in a **predicted class** while **each column** represents the instances in an **actual class** (and vice versa). \n",
    "\n",
    "Let us understand it with the help of an example. \n",
    "\n",
    "\n",
    "![confusion](https://storage.googleapis.com/ga-commit-live-stag-uat-data/account/b92/11111111-1111-1111-1111-000000000000/b376/03808ceb-2a3a-4828-9f7d-bdbe7a00c6a1/file.jpg)\n",
    "\n",
    "\n",
    "Before going through the calculations, lets understand some terms:\n",
    "- **True Positives (TP):** Actually `positive` and predicted `positive` (*CORRECT PREDICTIONS*)\n",
    "- **True Negatives (TN):** Actually `negative` and predicted `negative` (*CORRECT PREDICTIONS*)\n",
    "- **False Positives (FP):** Actually `negative` but predicted `positive` (*INCORRECT PREDICTIONS*)\n",
    "- **False Negatives (FN):** Actually `positive` but predicted `negative` (*INCORRECT PREDICTIONS*)\n",
    "\n",
    "In the above example with the binary outcome `Cat`($1$) or `Non-cat`($0$):\n",
    "- Actual number of **cats** = 8\n",
    "- Actual number of **non-cats** = 19\n",
    "\n",
    "Now, from the predictions based on model,\n",
    "- Predicted **cats** = $5 + 2 = 7$\n",
    "- Predicted **non-cats** = $3 + 17 = 20$\n",
    "\n",
    "So, \n",
    "\n",
    "- **TP** = 5 i.e. actual **cats** and also predicted **cats**.\n",
    "\n",
    "- **FP** = 2 i.e. actual **non-cats** but predicted **cats**.\n",
    "\n",
    "- **FN** = 3 i.e. actual **cats** but predicted **non-cats**.\n",
    "\n",
    "- **TN** = 17 i.e. actual **non-cats** and predicted **non-cats**.\n",
    "\n",
    "`Confusion matrix represents confusion on unseen data.`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Accuracy score, Precision, Recall and F score\n",
    "\n",
    "***\n",
    "\n",
    "#### Accuracy score \n",
    "\n",
    "It is the fraction of correct predictions to the total number of predictions on unseen data. Mathematically,\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + FP + TN + FN}$$\n",
    "\n",
    "Remember in our earlier example, **TP** = $5$, **FP** = $2$, **FN** = $3$, **TN** = $17$\n",
    "\n",
    "So, accuracy score = $\\frac{5 + 17}{5 + 2 + 3 + 17}$ = $\\frac{22}{27}$ = $0.8148$\n",
    "\n",
    "**When to use accuracy?**\n",
    "\n",
    "It is a relatively good metric where we have symmetric distribution of the targets. but cannot handle cases where predictions for one of the instances is very less. For example: In case of cancer detection, even if we sample data we will encounter very less cases of people having cancer ($1$). In such a case model will learn more about $0$s i.e. non-cancerous and will output a good accuracy score even though it has missed out some actual cancer cases or all of them!\n",
    "\n",
    "To resolve cases with unbalanced targets, precision, recall and f-1 score come in handy. You can use them according to the business requirement.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "For every predicted class, it is the fraction of the correct predictions to the total number of predictions for that class. It answers the question **Of all the values predicted as belonging to the class \"X\", what percentage is correct?** Mathematically,\n",
    "\n",
    "$$ Precision(P) = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "The precision in our example would be = $\\frac{5}{5 + 2} = \\frac{5}{7} = 0.7143 $\n",
    "\n",
    "**When to use precision?**\n",
    "\n",
    "Precision is a good measure to determine, when the costs of **False Positive is high**. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model.\n",
    "\n",
    "\n",
    "#### Recall \n",
    "\n",
    "For every actual class, it is the fraction of the number of correct predictions to the total number of actual instances of the class. It answers the question **Of all the instances of the class \"X\", what percentage did we predict correctly?** Mathematically,        \n",
    "\n",
    "$$ Recall(R) = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "The recall in our previous example is = $\\frac{5}{5 + 3} = \\frac{5}{8} = 0.625$\n",
    "\n",
    "**When to use recall?**\n",
    "\n",
    "Recall shall be the model metric we use to select our best model when there is a **high cost associated with False Negative**. For instance, in fraud detection or sick patient detection; if a fraudulent transaction (Actual Positive) is predicted as non-fraudulent (Predicted Negative), the consequence can be very bad for the bank.\n",
    "\n",
    "\n",
    "#### F score \n",
    "\n",
    "It is the harmonic mean of the precision and recall for a classifier. Mathematically, \n",
    "\n",
    "$$ F score = \\frac{2PR}{P + R}$$\n",
    "\n",
    "Now, the F-score is = $\\frac{2*0.7143*0.625}{0.7143 + 0.625} = \\frac{0.892875}{1.3393} = 0.67$\n",
    "\n",
    "**When to use F score?**\n",
    "\n",
    "If you want to achieve a balance between precision and recall, use F-1 score. But unfortunately, the F-score isn’t the holy grail and has its tradeoffs. It favors classifiers that have similar precision and recall. This is a problem because you sometimes want a high precision and sometimes a high recall. The thing is that an increasing precision results in a decreasing recall and vice versa. This is called the precision/recall tradeoff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find accuracy, precision, recall, f-score\n",
    "\n",
    "In this task you will calculate the accuracy score, precision, recall and f-score and also visualzise the confusion matrix to see how your classifier is performing. \n",
    "\n",
    "### Instructions\n",
    "- Use the `predictions` array and actual target labels `y_test` to calculate the confusion matrix accuracy, precision, recall, f-score and save them as `cf`, `acc`, `precision`, `recall` and `f_score` respectively\n",
    "- Go through official documentations for [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix), [F-1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score), [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score), [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) to look at the syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144   4]\n",
      " [ 14 113]]\n",
      "==================================================\n",
      "0.9345454545454546\n",
      "==================================================\n",
      "0.9658119658119658\n",
      "==================================================\n",
      "0.889763779527559\n",
      "==================================================\n",
      "0.9262295081967213\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# import packages\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# confusion matrix\n",
    "cf = confusion_matrix(y_test, pred)\n",
    "print(cf)\n",
    "print('='*50)\n",
    "\n",
    "# accuracy\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(acc)\n",
    "print('='*50)\n",
    "\n",
    "# precision\n",
    "precision = precision_score(y_test, pred)\n",
    "print(precision)\n",
    "print('='*50)\n",
    "\n",
    "# recall\n",
    "recall = recall_score(y_test, pred)\n",
    "print(recall)\n",
    "print('='*50)\n",
    "\n",
    "# F-score\n",
    "f_score = f1_score(y_test, pred)\n",
    "print(f_score)\n",
    "print('='*50)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Calculate `precision` as `precision_score(y_test, pred)`.Similarly repeat for others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `cf`, `precision`, `recall`, `acc` and `f_score`\n",
    "- Value for `cf`: `(cf == [[144, 4], [14, 113]]).sum() == 4`\n",
    "- Value for `acc`: `round(acc, 2) == 0.93`\n",
    "- Value for `precision`: `round(precision, 2) == 0.97`\n",
    "- Value for `recall`: `round(recall, 2) == 0.89`\n",
    "- Value for `f_score`: `round(f_score, 2) == 0.93`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ROC-AUC score\n",
    "\n",
    "***\n",
    "\n",
    "ROC stands for Receiver Operator Characteristic, is a curve that helps us visualize the performance of a binary classifier. The Area under curve (AUC) of the ROC curve indicates the ability of the binary classifier to distinguish between both the classes. It is calculated using all possible threshold probabilities unlike other metrics that use a fixed threshold.\n",
    "\n",
    "Now, let us understand this using the actual ROC diagram which is a graphical plot of **TPR** on the Y-axis and **FPR** on the X-axis for various threshold settings. The **TPR** is nothing but the recall term that we had already discussed whereas **FPR** is the term which which indicates how much the classifier incorrectly predicts a negative instance as positive.\n",
    "\n",
    "**Just for your information**\n",
    "\n",
    "**TPR** $=\\frac{TP}{TP + FN}$\n",
    "\n",
    "**FPR** $=\\frac{FP}{FP + FN}$ \n",
    " \n",
    "\n",
    "![roc_auc](https://storage.googleapis.com/ga-commit-live-stag-uat-data/account/b92/11111111-1111-1111-1111-000000000000/b929/877bd87c-e9f3-426d-9c71-6c635ce844eb/file.png)\n",
    "\n",
    "\n",
    "The top left image shows the two distributions of negatives (left side gaussian) and positives (right side gaussian) and the corresponding ROC curve below. The threshold is the vertical line in the top image. By moving the line from left to right, we obtain different thresholds, calculate the respective **TPR**s and **FPR**s and plot it on the ROC curves. **The AUC lies between 0 and 1.**\n",
    "\n",
    "Evaluate your classifier based on the AUC score according to:\n",
    "\n",
    "- .90-1 = excellent classifier\n",
    "- .80-.90 = good classifier\n",
    "- .70-.80 = fair classifier\n",
    "- .60-.70 = poor classifier\n",
    "- .50-.60 = fail classifier\n",
    "\n",
    "***\n",
    "\n",
    "Now let us understand why a low AUC score represents a bad classifier and vice-versa.\n",
    "\n",
    "\n",
    "<img src='../images/img.png'>\n",
    "\n",
    "\n",
    "In the first image, the classifier has an AUC score of $0.7$ whereas the lower one has $0.5$. Now, a higher AUC has classes which have a higher separation as evident from the image in the top left. More separation means for the same **FPR** the **TPR** is higher and vice-versa. An ideal classifier separates both the classes perfectly and as a result the **TPR** is $1$ and **FPR** is $0$. The worst classifer has an AUC score of $0.5$ which happends when it is unable to make distinction between the classes.\n",
    "\n",
    "**Advantages of using AUC score**\n",
    "\n",
    "- It is useful even if predicted probabilities are not properly calibrated. For instance our probabilities may lie in the range ($0.8, 0.95$). This would have no effect on the AUC score.\n",
    "- Useful metric even if the classes are imbalanced.\n",
    "\n",
    "***\n",
    "\n",
    "### Example\n",
    "\n",
    "In our previous (cat vs non-cat) example, we had **TP** = $5$, **FP** = $2$, **FN** = $3$ and **TN** = $17$. Here, **TPR** = $0.625$ and **FPR** = $0.12$ for a threshold of $0.5$. Lets say that we have the following data for the different thresholds and their corresponding **FPR**s and **TPR**s\n",
    "\n",
    "| Threshold | FPR | TPR |\n",
    "| --- | --- | --- | \n",
    "| 0.06 | 0.05 | 0.15 |\n",
    "| 0.1 | 0.1 | 0.54 |\n",
    "| 0.3 | 0.45 | 0.7 |\n",
    "| 0.45 | 0.5 | 0.8 |\n",
    "| 0.6 | 0.54 | 0.85 |\n",
    "| 0.85 | 0.78 | 0.92 |\n",
    "| 0.95 | 0.9 | 0.93 |\n",
    "\n",
    "Plotting them in a X-Y plot we get the following graph:\n",
    "\n",
    "![img](https://storage.googleapis.com/ga-commit-live-stag-uat-data/account/b92/11111111-1111-1111-1111-000000000000/b675/bf5673e5-52a4-43a7-8c30-6721fc537584/file.png)\n",
    "\n",
    "\n",
    "The blue shaded region represents the **AUC** with **FPR** and **TPR** on the X-axis and Y-axis respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate AUC\n",
    "\n",
    "In this task calculate the `AUC` score using scikit-learn's function\n",
    "\n",
    "### Instructions\n",
    "- Calculate the ROC AUC score using scikit learn and save it as `roc`. Go through its official [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9313683762502661\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Code starts here\n",
    "roc = roc_auc_score(y_test, pred)\n",
    "print(roc)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Syntax is `roc_auc_score(y_test, pred)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- variable declaration for `roc`\n",
    "- Value for `roc`: `round(roc, 2) == 0.93`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept End Quiz\n",
    "\n",
    "1. Which of the following evaluation metrics can not be applied in case of logistic regression output to compare with target?\n",
    "\n",
    "    a. AUC-ROC\n",
    "    \n",
    "    b. Accuracy\n",
    "    \n",
    "    c. Log-loss\n",
    "    \n",
    "    d. RMSE\n",
    "    \n",
    "**Ans:** d. RMSE; it is a metric for regression problems not classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept end quiz\n",
    "\n",
    "1. Logistic regression is a linear model.\n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS** a. TRUE\n",
    "\n",
    "2. Which of the following metrics can be used for classification tasks?\n",
    "\n",
    "    a. MSE\n",
    "    \n",
    "    b. None of these\n",
    "    \n",
    "    c. F-1 score\n",
    "    \n",
    "    d. RMSE\n",
    "    \n",
    "**ANS** c. F-1 score\n",
    "\n",
    "3. Is sigmoid a linear function?\n",
    "\n",
    "    a. YES\n",
    "    \n",
    "    b. NO\n",
    "    \n",
    "**ANS** b. NO\n",
    "\n",
    "4. Given enough time, gradient descent is guaranteed to find the optimal global solution in logistic regression. \n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS**: a. TRUE\n",
    "\n",
    "5. Standardisation of features is required before training a Logistic Regression.\n",
    "    \n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS** b. FALSE\n",
    "\n",
    "6. What is the range of the logit (logarithm of odd ratio) function?\n",
    "\n",
    "    a. (0,1)\n",
    "    \n",
    "    b. ($-\\infty$, $\\infty$)\n",
    "\n",
    "7. Odds ratio is 1. What is the probability?\n",
    "\n",
    "    a. 0\n",
    "    \n",
    "    b. 0.5\n",
    "    \n",
    "    c. 1\n",
    "    \n",
    "    d. 0.75\n",
    "    \n",
    "**ANS** b. 0.5\n",
    "\n",
    "8. ROC curve represents ability of classifier to separate classes\n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS** a. TRUE\n",
    "\n",
    "9. One-vs-rest classification can deal with imbalanced classes. \n",
    "\n",
    "    a. TRUE\n",
    "    \n",
    "    b. FALSE\n",
    "    \n",
    "**ANS** b. FALSE\n",
    "\n",
    "10. Recall represents\n",
    "\n",
    "    a. Of all instances belonging to a certain class how much we did correctly\n",
    "    \n",
    "    b. Of all instances being predicted to a certain class how much we did correctly\n",
    "    \n",
    "**ANS** a. Of all instances belonging to a certain class how much we did correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
