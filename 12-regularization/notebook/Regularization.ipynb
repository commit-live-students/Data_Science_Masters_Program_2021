{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "***\n",
    "\n",
    "## Description\n",
    "\n",
    "Learn about the gradient descent optimization algorithm and its types; and why it is needed to reduce the number of features, how to do it using regularization and its different types.\n",
    "\n",
    "***\n",
    "\n",
    "## Overview\n",
    "- Gradient descent and its types\n",
    "- Bias and variance\n",
    "- Model complexity\n",
    "- Regularization\n",
    "- Types of regularization\n",
    "- Cross validation\n",
    "- Hyperparameter tuning\n",
    "\n",
    "***\n",
    "\n",
    "## Pre-requisite\n",
    "\n",
    "- Python (NumPy, Pandas, matplotlib)\n",
    "- Differential Calculus\n",
    "- Linear Regression\n",
    "\n",
    "***\n",
    "\n",
    "## Learning Objectives\n",
    "- What is gradient descent and its different types\n",
    "- Understanding bias-variance trade-off in data\n",
    "- Use regularization to control overfitting\n",
    "- L1 and L2 regularization\n",
    "- Effective use of cross-validation and hyperparameter tuning to improve results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Gradient Descent\n",
    "\n",
    "### Description: Learn the importance of gradient descent, what it is and its different variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Intuition behind gradient descent\n",
    "\n",
    "***\n",
    "\n",
    "The bivariate linear regression model can be expressed as  $\\mathbf{y} = \\theta_0 + \\theta_1 \\mathbf{x}$ . You can estimate the value of the regression parameters ( $\\theta_0$  and  $\\theta_1$ ) using the Ordinary Least Squares(OLS) method of optimization. However, there is another method very widely used for estimating these parameters which is known as **Gradient Descent**. But before getting into the nuts and bolts of this method lets understand why we need gradient descent in the first place.\n",
    "\n",
    "\n",
    "**Why Gradient Descent when we already have OLS?**\n",
    "\n",
    "There are a few reasons why algorithms like gradient descent are preferred over OLS for parameter estimation.\n",
    "- The OLS method is an expensive process as it involves matrix inversion. As the amount of data increases, this operation becomes more complex (algorithmic complexity is $O(n^3$)) and hence it scales poorly\n",
    "- Most non-linear trends do not have a closed form solution where OLS will fail to find parameters. \n",
    "\n",
    "\n",
    "**Intuition of gradient descent**\n",
    "\n",
    "Consider the below image: <img src='../images/intuition.jpg' width=600>\n",
    "\n",
    "These three pictures represent three different situations where a ball is placed in a glass bowl at three separate positions. It is a known fact that the force of gravity will pull the ball towards the bottom of the bowl.\n",
    "\n",
    "In **situation 1**, the ball will move from position b1 to c1 and not a1. This ball will continue to travel till it reaches the bottom of the bowl. In situation 2, since the static ball is already at the bottom it will stay at b2 and it won’t move at all. In general, **the ball always tries to move from a higher potential energy state to a lower state**. Gravity is responsible for these different potential energy states of the ball.\n",
    "\n",
    "But how is this similar to gradient descent optimization? Actually, this is exactly how gradient descent optimization works. **The only major difference is that gradient descent optimization tries to minimize a loss function instead of potential energy**. (If you remember the loss function in OLS was minimizing the sum of squared residuals)\n",
    "\n",
    "Now, lets understand how the ball will roll down when it is placed in situation 1 and why does it so. In terms of the coordinate system, the potential energy reduces as the ball rolls down the Z-axis (vertical axis). The ball tries to modify its position on the X and Y-axes to determine the lowest possible potential energy or the minimum possible value on the z-axis.\n",
    "\n",
    "<img src='../images/situation.jpg' width=300>\n",
    "\n",
    "\n",
    "The gradient descent optimization can be thought of as a process similar to the rolling example in the following manner:\n",
    "- **Z-axis can be considered as the loss function**\n",
    "- **X &  Y-axes are the coefficients of the model** \n",
    "- **Loss function is equivalent to the potential energy of the ball in the bowl**\n",
    "- **Idea is to minimize loss function by adjusting X & Y-axes (i.e coefficients of the model)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gradient Descent: An iterative approach to find minimum\n",
    "\n",
    "***\n",
    "\n",
    "Remember how you used differential calculus to find the minimum value of a function? In case you've forgotten or don't know about differential calculus do not worry, we are providing a simple example below to help you come to terms with it.\n",
    "\n",
    "Let's solve for the minimum value of the function  $f(x) : x^{4}-10x^{2}+9$  \n",
    "\n",
    "The plot for the function is shown below where the yellow and green dotted vertical lines represent the values of x for which the function has the least value.\n",
    "\n",
    "<img src='../images/fig.png'>\n",
    "\n",
    "You can find it with the help of differential calculus in the following way:\n",
    "\n",
    "1. Differentiate with respect to $x$ and set this value to $0$. Solve for $x$ in this step\n",
    "\n",
    "$$\\frac{d}{dx}f(x)= 4 x^{3}-20x = 0$$\n",
    "\n",
    "2. Solving gives values of $x$ for which the function $f(x)$ has minimum values. The value of $x$ thus found is $x = \\pm \\sqrt{5} =\\pm 2.24$ \n",
    "\n",
    "The method that we have shown just now is the **logical method**. While this method is pretty simple and straightforward, but unfortunately for a lot of complicated functions, it is not possible to solve equations this way. So we need to identify some numeric methods to solve such equations which require iterative calculations. \n",
    "\n",
    "\n",
    "**ITERATIVE METHOD**\n",
    "\n",
    "Lets start with initial value of $x = 5$ for the function $f(x) : x^{4}-10x^{2}+9$ with a learning rate ($\\alpha = 0.001$). **The learning rate controls how much we are adjusting the weights with respect to the loss gradient. The lower the value, the slower we travel along the downward slope and vice-versa.** \n",
    "\n",
    " The gradient of the function for any value of x is:  $\\frac{d}{dx}(f(x)) = 4x^3 - 20x$ \n",
    "\n",
    "*FIRST ITERATION*\n",
    "\n",
    "At x = 5, the gradient is  $4.5^3 - 20.5 = 600 - 100 = 500$ \n",
    "\n",
    "Now we decrease x by an amount equal to the product of the learning rate i.e.  $\\alpha$  and the gradient at that point.\n",
    "\n",
    "So, new value of x is:  $x = 5 - 0.001*500 = 5 - 0.5 = 4.5$ \n",
    "\n",
    "**This is the new value of x at the end of the first iteration**\n",
    "\n",
    "\n",
    "*SECOND ITERATION*\n",
    "\n",
    "Following the same procedure as the first one we have,\n",
    "\n",
    "New value of x is:  $x = 4.5 - 0.001*(4.4.5^3 - 20*4.5) = 4.2255$ \n",
    "\n",
    "If we continue doing iterations in this way, it is possible to arrive the minimum value i.e. $\\sqrt{5}$.\n",
    "\n",
    "\n",
    "**Python implementation**\n",
    "\n",
    "A Pythonic implementation is shown below:\n",
    "```python\n",
    "# Algorithm starts at x = 5\n",
    "x_0 = 5\n",
    "\n",
    "# Learning Rate\n",
    "rate = 0.001\n",
    "\n",
    "# Stopping criteria for gradient descent\n",
    "precision = 0.0001 \n",
    "\n",
    "# Difference between current x and new x\n",
    "diff = 1\n",
    "\n",
    "# Maximum number of iterations\n",
    "max_iters = 10000\n",
    "\n",
    "# Number of iterations we performed\n",
    "iters = 0\n",
    "\n",
    "# Lambda function for calculating gradient\n",
    "df = lambda x: 4*(x)**3 - (20*x)\n",
    "\n",
    "'''Loop till difference between previous and new x-value is greater than precision\n",
    "    and number of iterations performed is less than the maximum number of iterations'''\n",
    "\n",
    "while diff > precision and iters < max_iters:\n",
    "    # Old x-value\n",
    "    prev_x = x_0\n",
    "    # New x-value \n",
    "    x_0 = x_0 - rate*df(prev_x)\n",
    "    # Absolute difference between old and new x-values\n",
    "    diff = abs(x_0 - prev_x)\n",
    "    # Increment number of iterations performed by 1\n",
    "    iters += 1\n",
    "    if not iters%12:\n",
    "        print(\"Iteration {}: x = {}\".format(iters, x_0))\n",
    "\n",
    "print('='*50)\n",
    "\n",
    "print(\"Global minima is at x = {}\".format(x_0))\n",
    "```\n",
    "\n",
    "The output is:\n",
    "\n",
    "```python\n",
    "Iteration 12: x = 3.0859858700832468\n",
    "Iteration 24: x = 2.650430113743793\n",
    "Iteration 36: x = 2.463011882474194\n",
    "Iteration 48: x = 2.3668266660505166\n",
    "Iteration 60: x = 2.3133970293306554\n",
    "Iteration 72: x = 2.2824663690748417\n",
    "Iteration 84: x = 2.264141835908863\n",
    "Iteration 96: x = 2.2531388781091835\n",
    "Iteration 108: x = 2.2464792668057707\n",
    "Iteration 120: x = 2.2424291258463547\n",
    "Iteration 132: x = 2.2399588108854416\n",
    "Iteration 144: x = 2.2384494200813188\n",
    "==================================================\n",
    "Global minima is at x = 2.2384494200813188\n",
    "```\n",
    "The loss function also decreases as the number of iterations increases and ultimately it stops after finding the optimum value of $x$ at which the loss is minimum as depicted by the image below:\n",
    "\n",
    "<img src='../images/loss.png'>\n",
    "\n",
    "\n",
    "**Analogy of the iterative method with a rolling ball**\n",
    "\n",
    "The iterative method is similar to rolling a ball downwards, and measuring its position with each calculation till it reaches the bottom. The idea is to measure the speed of the ball based on the gradient or the slope of the curve. \n",
    "\n",
    "In the next topic you will learn how gradient descent optimization is used with linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{1}{2m}(X\\theta - y)^T(X\\theta - y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Gradient Descent: A mathematical approach\n",
    "\n",
    "***\n",
    "\n",
    "In the previous topic you got a brief understanding to the gradient descent approach. Now lets deep dive and break it into four steps to simplify the entire process intuitively and mathematically. The entire method can be broken down into four steps which are discussed in detail below.\n",
    "\n",
    "\n",
    "**Steps of gradient descent**\n",
    "\n",
    "Given a machine learning model with parameters (weights i.e.  $\\theta$ ) and a cost function ( $J(\\theta)$ , find a good set of weights for our model which minimizes the cost function. The step-wise procedure would be:\n",
    "- Start with some initial set of values for our model parameters (weights and bias) where our goal is finding the best set of model parameters by iterations \n",
    "- Calculate the gradient(**G**) of the cost function at the current set of model parameters as well as the cost function to find the direction of decreasing cost function. This is the ideal direction which gives us the best model paramters\n",
    "- Update the weights by an amount proportional to the calculated gradient (**G**) at the current set of model parameters i.e.  $\\theta = \\theta − \\eta G$ \n",
    "- Repeat the second and third steps until the cost function stops reducing or in other words you have arrived at the global minima\n",
    "\n",
    "The image below describes exactly what gradient descent aspires to do: <img src='../images/gd.png' width=400>\n",
    "\n",
    "\n",
    "**Calculating gradient descent**\n",
    "\n",
    "In linear regression lets assume we have an output variable $\\mathbf{y}$ which depends linearly on the input vector $\\mathbf{x}$ with m instances and n features. Matrix  $\\mathbf{x}$  is also the matrix consisting of all the feature vectors. We approximate  $\\mathbf{y}$  by\n",
    "$$ \\mathbf{y} = h_\\theta(\\mathbf{x}) = \\theta^T\\mathbf{x} = \\sum_{i=1}^{n}\\theta_ix_i$$\n",
    "\n",
    "The cost function $J(\\theta)$ is : $$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^{n}(h_\\theta(x^{(i)})−y^{(i)})^2$$\n",
    "\n",
    "The four steps described in the previous topic are expanded below:\n",
    "\n",
    "1. **Initialize model parameters ( $\\theta$ )**: Lets initialize a set of model parameters $\\theta$. We will be continually making improvements to the set to arrive at the best combination\n",
    "\n",
    "2. **Calculate gradients**: You will be calculating the gradient of the cost function ($J(\\theta)$) to find the direction of minimizing cost function. Since there are a lot of model parameters ($\\theta_i = 1$ to $\\theta_i  = n$), we will calculate gradients for every model parameter ($\\theta_i$) by partial differentiation of the cost function($J(\\theta)$) with respect to a particular model parameter ($\\theta_i$). Lets look how we do that mathematically for a single training example:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = \\frac{\\partial }{\\partial \\theta_j}(h_\\theta(x) - y)^2$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = 2.\\frac{1}{2}.(h_\\theta(x) - y)).\\frac{\\partial }{\\partial \\theta_j}(h_\\theta(x) - y)$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = (h_\\theta(x) - y)).\\frac{\\partial }{\\theta_j}(\\sum_{i=1}^{n}\\theta_ix_i)$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = (h_\\theta(x) - y)).x_j$$\n",
    "\n",
    "\n",
    " The right hand side is the gradient and you calculate the value for this gradient with the current model parameters. Since this is the gradient for only a single training example, in order to find the overall gradient of the batch simply the gradients of all the training examples.\n",
    "    \n",
    "3. **Update weights**: Now time to update weights with an amount proportional to the gradient. The proportionality constant is defined by the parameter $\\alpha$ also called the learning rate. Lets look at how to this with a single training example:\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha.(h_\\theta(x) - y)).x_j$$\n",
    "\n",
    "For $m$ training examples we have:\n",
    "\n",
    "$\\text{Repeat until convergence:}$  ${\\theta_j = \\theta_j - \\alpha.\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})).x_j^{(i)}}$ $\\text{for every j}$\n",
    "\n",
    " This weight update rule is intuitive because more correct is our prediction, lesser is the term $(h_\\theta(x) - y))$ and vice-versa.\n",
    " \n",
    "\n",
    "4. **Repitition of steps 2 and 3**: Repeat steps two and three until convergence occurs.\n",
    "\n",
    "**Since this approach updates weigths by taking all the training examples into account, it is also called BATCH GRADIENT DESCENT.**\n",
    " \n",
    " *NOTE:* **Calculate the gradients in second step by going through the entire batch of training examples and then use it to update weights.**\n",
    "\n",
    "\n",
    "**Batch Gradient Descent with a toy dataset**\n",
    "\n",
    "A toy dataset with $100$ instances is given consisting of a single feature and a continuous target. The first five rows look somewhat like this: <img src='../images/toy.png'>\n",
    "\n",
    "Now lets have a look at the scatter-plot for distributions of **'Target'** and **'Feature'**. The scatter plot looks like: <img src='../images/scatter.png'>\n",
    "\n",
    "Python implementation with NumPy for calculating gradient descent is given below:\n",
    "\n",
    "```python\n",
    "def gradient_descent(alpha, x, y, numIterations):\n",
    "    '''\n",
    "    Arguments:\n",
    "        alpha---> learning rate\n",
    "        x---> features\n",
    "        y---> target\n",
    "        numIterations---> number of iterations\n",
    "    Returns:\n",
    "        theta---> model parameters\n",
    "    '''\n",
    "    # number of samples\n",
    "    m = x.shape[0]\n",
    "    # initialize model parameters\n",
    "    theta = np.ones(2)\n",
    "    # transpose design matrix\n",
    "    x_transpose = x.transpose()\n",
    "    # Iterate over the entire batch\n",
    "    for iters in range(1, numIterations+1):\n",
    "        # Predicted target\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        # Loss\n",
    "        loss = hypothesis - y\n",
    "        # Cost function\n",
    "        J = np.sum(loss ** 2) / (2 * m)\n",
    "        # Calculate gradient\n",
    "        gradient = np.dot(x_transpose, loss) / m\n",
    "        # Update model parameters\n",
    "        theta = theta - alpha * gradient\n",
    "        if not iters%200:\n",
    "            print(\"Iteration {} | J: {}\".format(iters, J))\n",
    "    print('='*50)\n",
    "    return \"Final thetas are {} and {}\".format(theta[0], theta[1])\n",
    "```\n",
    "\n",
    "After running the above code on the toy dataset with $5000$ iterations and $0.01$ learning rate, the output was:\n",
    "```python\n",
    "Iteration 0 | J: 1604.873080714912\n",
    "Iteration 200 | J: 715.2500524101275\n",
    "Iteration 400 | J: 699.5977423555787\n",
    "Iteration 600 | J: 699.3061763021875\n",
    "Iteration 800 | J: 699.3004712673605\n",
    "Iteration 1000 | J: 699.3003552586653\n",
    "Iteration 1200 | J: 699.3003528330281\n",
    "Iteration 1400 | J: 699.3003527813338\n",
    "Iteration 1600 | J: 699.3003527802181\n",
    "Iteration 1800 | J: 699.3003527801936\n",
    "Iteration 2000 | J: 699.3003527801934\n",
    "Iteration 2200 | J: 699.3003527801932\n",
    "Iteration 2400 | J: 699.3003527801935\n",
    "Iteration 2600 | J: 699.3003527801934\n",
    "Iteration 2800 | J: 699.3003527801934\n",
    "Iteration 3000 | J: 699.3003527801932\n",
    "Iteration 3200 | J: 699.3003527801934\n",
    "Iteration 3400 | J: 699.3003527801934\n",
    "Iteration 3600 | J: 699.3003527801934\n",
    "Iteration 3800 | J: 699.3003527801934\n",
    "Iteration 4000 | J: 699.3003527801934\n",
    "Iteration 4200 | J: 699.3003527801934\n",
    "Iteration 4400 | J: 699.3003527801934\n",
    "Iteration 4600 | J: 699.3003527801934\n",
    "Iteration 4800 | J: 699.3003527801934\n",
    "==================================================\n",
    "'Final thetas are -2.84963639 and 43.20424388'\n",
    "```\n",
    "\n",
    "You can also visualize gradient descent somewhat like this where you are going in the direction of decreasing cost with every ellipse denoting regions with similar cost. <img src='../images/vectorized.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Stochastic Gradient Descent\n",
    "\n",
    "***\n",
    "\n",
    "The flow of **Batch Gradient Descent** approach is: <img src='../images/gdflow.png'> \n",
    "\n",
    "Although this approach of using the entire batch of training examples to update weights every time makes complete sense, with increasing number of training instances it will become more cumbersome to update model parameters. This will result in exploding training time which should be avoided using some techniques. \n",
    "\n",
    "A simple workaround is; *\"Instead of using the entire batch for training, use a single randomly selected instance for calculating gradient and update the model parameters.\"* This approach is called as **Stochastic Gradient Descent (SGD)** as the gradient calculated this way is a stochastic approximation to the gradient calculated using the entire training data. Each update is now much faster to calculate than in batch gradient descent, and over many updates, we will head in the same general direction. \n",
    "\n",
    "In SGD, with every  iteration, you need to shuffle the training set and pick a random training example from that.\n",
    "Since, you'll be using one training example, your path to the local minima will be very noisy like a drunk man after having one too many drinks. \n",
    "\n",
    "The flow of **SGD** can be summarized as: <img src='../images/sgcflow.png'>\n",
    "\n",
    "\n",
    "**Pythonic implementation of SGD**\n",
    "\n",
    "Now lets look at the Pythonic implementation of Stochastic Gradient Descent\n",
    "```python\n",
    "def sgd(alpha, x, y, numIterations):\n",
    "    '''\n",
    "    Arguments:\n",
    "        alpha ---> Learning rate\n",
    "        x ---> Features\n",
    "        y ---> Target\n",
    "        numIterations ---> Number of Iterations\n",
    "    Returns:\n",
    "        '''\n",
    "    # Number of training instances\n",
    "    m = x.shape[0]\n",
    "    # Initial thetas\n",
    "    theta = np.ones(2)\n",
    "    # Iterate till a desired number\n",
    "    for iters in range(numIterations):\n",
    "        # Pick a random number\n",
    "        index = np.random.randint(m)\n",
    "        # Random training instance (both feature and target)\n",
    "        x_random = x[index].transpose()\n",
    "        y_random = y[index]\n",
    "        # Prediction for random instance\n",
    "        y_pred = np.dot(x_random, theta)\n",
    "        # Loss for random instance\n",
    "        loss = y_pred - y_random\n",
    "        # Cost for random instance\n",
    "        J = loss**2 / (2*m)\n",
    "        # Gradient for random instance\n",
    "        gradient = np.dot(x_random, loss) / m\n",
    "        # Update theta based on gradient\n",
    "        theta = theta - alpha*gradient\n",
    "        if not iters%1000:\n",
    "            print(\"Iteration {} | J : {}\".format(iters, J))\n",
    "    print('='*50)\n",
    "    return \"Final thetas are {} and {}\".format(theta[0], theta[1])\n",
    "```\n",
    "\n",
    "The function outputs the following when run with the toy dataset with the same $50000$ and $0.01$ learning rat:\n",
    "```python\n",
    "Iteration 0 | J : 21.26804415031862\n",
    "Iteration 1000 | J : 9.23721020080173\n",
    "Iteration 2000 | J : 0.053554520449303464\n",
    "Iteration 3000 | J : 15.312069883348792\n",
    "Iteration 4000 | J : 0.705699298171491\n",
    "..................................\n",
    "..................................\n",
    "Iteration 45000 | J : 1.2920779852293338\n",
    "Iteration 46000 | J : 11.957135340910568\n",
    "Iteration 47000 | J : 0.12814469793457733\n",
    "Iteration 48000 | J : 0.0006467831314213575\n",
    "Iteration 49000 | J : 10.091530655370994\n",
    "==================================================\n",
    "'Final thetas are -2.757638863381235 and 42.76226358622706'\n",
    "```\n",
    "\n",
    "As you can see the thetas obtained by SGD are almost similar as that by Batch Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Learning Rate, Feature Scaling and Mini-batch Gradient Descent\n",
    "\n",
    "***\n",
    "\n",
    "**Impact of learning rate**\n",
    "\n",
    "Learning rate is the amount by which you move down in the direction of decreasing cost denoted usually by $\\alpha$. If $\\alpha$ is too big, then there might be a possibility to overshoot the minima. On the other hand on choosing a smaller learning rate the learning algorithm might take too much time to learn from the data which will make our model slower. So, choosing a **good** learning rate which reaches the lowest cost swiftly is of prime importance with an iterative approach like gradient descent.\n",
    "\n",
    "<img src='../images/lr.png' >\n",
    "\n",
    "\n",
    "**Feature Scaling in gradient descent**\n",
    "\n",
    "You must be thinking what role does the scale of features play in gradient descent? From the previous sections we have the weight update rule for batch gradient descent as : \n",
    "$$\\theta_j = \\theta_j - \\alpha.(h_\\theta(x) - y)).x_j$$\n",
    "\n",
    "Observe that updates are dependent on the feature magnitude $x_j$. If all the features are not on the same scale, this might lead to some weights getting updated faster than others; slowing down the entire process of gradient descent. The way to tackle this obstacle would be normalizing the features which will give us an even contour to navigate and we can find the best set of model parameters pretty quickly. \n",
    "\n",
    "Lets take a situation with two features having coefficients $\\theta_1$ and $\\theta_2$ and cost $J(\\theta)$. In case of unscaled features, we have the contour with an elliptical/oval shape. This shape makes it very difficult for the model to arrive at the optimum $\\theta$s and takes a long time to do so. <img src='../images/without.png'>\n",
    "\n",
    "Upon normalizing the features, we obtain a more even contour and the model can quickly arrive at the best set of model parameters ($\\theta$s) in lesser time as compared with the situation with non-normalized features. \n",
    "<img src='../images/with.png'>\n",
    "\n",
    "\n",
    "**Initializing model parameters**\n",
    "\n",
    "Weight/parameter initialization is a key step in gradient descent. This is because a close initial guess can lead to faster convergence and a bad guess can lead to a much longer time. It is almost like shooting a target in the dark. Only with domain expertise one can have an approximation for the model parameters. \n",
    "\n",
    "\n",
    "**Mini-batch Gradient Descent**\n",
    "\n",
    "Till now you have come across two variants of gradient descent: Batch and Stochastic. There is another very useful variant which falls somewhere between them is the **Mini-Batch** variant. Here, instead of iterating over all training examples or a single training example, we process n training examples at once. This is a good choice for very large data sets. For example we can take 16, 32, 128 etc as the sample size of the mini-batch for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. If the learning rate is too small, then gradient descent may take a very long time to converge. True or False?\n",
    "\n",
    "    A. TRUE\n",
    "    \n",
    "    B. FALSE\n",
    "    \n",
    "**ANS**: A. TRUE\n",
    "\n",
    "**EXPLAINATION**: If the learning rate is small, gradient descent ends up taking an extremely small step on each iteration, and therefor can take a long time to converge\n",
    "\n",
    "\n",
    "2. Does gradient descent always find the global minima?\n",
    "\n",
    "    A. TRUE\n",
    "    \n",
    "    B. FALSE\n",
    "    \n",
    "**ANS**: B. FALSE\n",
    "\n",
    "**EXPLAINATION**: Gradient descent might get stuck at local minima since the gradient is zero at that point\n",
    "\n",
    "\n",
    "3. Stochastic gradient descent takes less time than gradient descent to train considering the fact that the same number of iterations are performed for each type?\n",
    "\n",
    "    A. TRUE\n",
    "    \n",
    "    B. FALSE\n",
    "    \n",
    "**ANS**: A. TRUE\n",
    "\n",
    "**EXPLAINATION**: Since SGD takes single training example to update weights, it takes less time to train on the same number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Why regularization\n",
    "\n",
    "***\n",
    "\n",
    "### Description: In this chapter, you will see what leads us to perform regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Polynomial Features\n",
    "\n",
    "***\n",
    "\n",
    "**Dataset**: During the entire concept we will be using the same housing dataset as we did for Linear Regression. In total we have 114 features (you can read about them in the text file provided) from which you have to predict the `SalePrice` of the houses.\n",
    "\n",
    "<!--- Missing values for numerical columns were imputed by median\n",
    "- Skewed features were log transformed to lessen the impact of outliers\n",
    "- Dummy variables were created for categorical features with One-Hot-Encoding\n",
    "- Numerical features were standardized i.e. 0 mean and unit variance\n",
    "- Dataset into train and test sets-->\n",
    "\n",
    "A lot of preprocessing is done so that you can focus more on the algorithm since this is the first time you will be learning about regularization. You will learn later the techniques to preprocess data and prepare it for machine learning. \n",
    "\n",
    "\n",
    "**Why Polynomial features**\n",
    "\n",
    "The hypothesis in linear regression is that the features at our disposal have a linear relationship with the target. But what if during visual inspection of relationships (take a scatter plot) you observe that the relationship is not actually linear but of some other type. Apart from that multicollinearity may also exist between predictor variables. In such a case the model becomes highly unstable and small changes to the data can cause large changes to the model. \n",
    "\n",
    "Also, during the inspection of residuals if you try to fit a linear model to curved data, a scatter plot of residuals (Y axis) on the predictor (X axis) has patches of many positive residuals in the middle, and patches of negative residuals at either end (or vice versa).  This is a good sign that a linear model is not appropriate, and a polynomial may do better. Here rises the need for polynomial features. \n",
    "\n",
    "\n",
    "**Polynomial function**\n",
    "\n",
    "In statistics, polynomial regression is a form of regression analysis in which the relationship between the independent variable `x` and the dependent variable `y` is modelled as an $n$th degree polynomial in `x`. \n",
    "\n",
    "The equation is $y = \\beta_0 + \\beta_1x + \\beta_2x^2 + \\beta_3x^3 + .... + \\beta_nx^n$\n",
    "\n",
    "Here, we are considering a single independent variable `x`. We can also have multiple independent features ($x_1, x_2, ...., x_n$)\n",
    "\n",
    "\n",
    "**Examples of polynomial functions**\n",
    "\n",
    "<img src='../images/polynomial.jpg' width=500>\n",
    "\n",
    "\n",
    "**Don't consider polynomial functions as non-linear functions**\n",
    "\n",
    "Now you might think that since the relationship between independent and dependent variables is no longer linear this new type of function is a non-linear function. Wrong! This is a linear model since the function itself is still a linear combination of weights.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add polynomial features\n",
    "\n",
    "In this task you will be adding some polynomial features to the dataset. Specifically, the square and cubic power for every feature except `GarageScore` has been calculated and saved as columns in `X_train` and `X_test`. You will make two new features `GarageScore-2` and `GarageScore-3` which stores the square and cubic power for the values of `GarageScore` for both the training and test sets\n",
    "\n",
    "### Instructions\n",
    "- The dataframes have been loaded for you and split into train-test features and targets as `X_train`, `X_test`, `y_train` and `y_test`\n",
    "- First normalize the training and test target i.e. both `y_train` and `y_test` by applying logarithmic transformation with `np.log1p()` which calculates the logarithm of $1 + x$. Save them as `y_train` and `y_test`\n",
    "- Take the square and cubic power to create two different features for `'GarageScore'` and save them as `GarageScore-2` for squares and `GarageScore-3` for cubes for both the training and test features\n",
    "- Print the first five observations from the training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotFrontage   LotArea    Street  LotShape  Utilities  LandSlope  \\\n",
      "0    -1.719611  0.533111  0.062776 -0.930396   0.031342   0.226584   \n",
      "1     0.466850  0.031176  0.062776  0.670860   0.031342   0.226584   \n",
      "2     0.676510 -0.276651  0.062776  0.670860   0.031342   0.226584   \n",
      "3     1.155734  0.628531  0.062776  0.670860   0.031342   0.226584   \n",
      "4     0.856219  0.952951  0.062776 -0.930396   0.031342   0.226584   \n",
      "\n",
      "   OverallQual  OverallCond  YearBuilt  YearRemodAdd      ...        \\\n",
      "0    -0.057773     0.475169  -1.774728      0.436282      ...         \n",
      "1    -0.793658    -0.420536  -0.338370     -1.221294      ...         \n",
      "2    -0.793658    -1.479930  -0.306101     -1.172541      ...         \n",
      "3     2.885765    -0.420536   1.129221      1.070061      ...         \n",
      "4    -0.057773    -0.420536   1.160750      1.070061      ...         \n",
      "\n",
      "   ExterQual-2  ExterQual-3  GarageCars-2  GarageCars-3  TotalBath-2  \\\n",
      "0     0.462829    -0.314869      0.108235      0.035608     0.068016   \n",
      "1     0.462829    -0.314869      0.108235      0.035608     0.068016   \n",
      "2     0.462829    -0.314869      5.587151    -13.206434     0.068016   \n",
      "3     6.509608    16.608572      2.806779      4.702321     1.065871   \n",
      "4     1.206093     1.324558      2.806779      4.702321     0.148846   \n",
      "\n",
      "   TotalBath-3  KitchenQual-2  KitchenQual-3  GarageScore-2  GarageScore-3  \n",
      "0    -0.017739       0.591118       0.454477       0.012137      -0.001337  \n",
      "1    -0.017739       0.602835      -0.468056       0.000357      -0.000007  \n",
      "2    -0.017739       0.602835      -0.468056       4.505913      -9.564764  \n",
      "3     1.100416       5.355100      12.392285       2.144093       3.139536  \n",
      "4     0.057426       0.591118       0.454477       0.857046       0.793426  \n",
      "\n",
      "[5 rows x 309 columns]\n",
      "   LotFrontage   LotArea    Street  LotShape  Utilities  LandSlope  \\\n",
      "0    -0.521550 -0.611301  0.062776 -0.930396   0.031342   0.226584   \n",
      "1     1.934474  0.539121  0.062776 -0.930396   0.031342   0.226584   \n",
      "2     3.491952  1.027213  0.062776 -0.930396   0.031342   0.226584   \n",
      "3     0.077480 -0.254034  0.062776  0.670860   0.031342   0.226584   \n",
      "4     0.077480 -0.460209  0.062776  0.670860   0.031342   0.226584   \n",
      "\n",
      "   OverallQual  OverallCond  YearBuilt  YearRemodAdd      ...        \\\n",
      "0     0.678111    -0.420536   1.097676      1.021309      ...         \n",
      "1     2.149880    -0.420536   1.160750      1.070061      ...         \n",
      "2     1.413996    -0.420536   0.781359      0.533787      ...         \n",
      "3     1.413996     0.475169   1.160750      1.070061      ...         \n",
      "4     2.149880    -0.420536   1.097676      0.972557      ...         \n",
      "\n",
      "   ExterQual-2  ExterQual-3  GarageCars-2  GarageCars-3  TotalBath-2  \\\n",
      "0     1.206093     1.324558      0.108235      0.035608     0.068016   \n",
      "1     1.206093     1.324558      0.108235      0.035608     0.068016   \n",
      "2     1.206093     1.324558      2.806779      4.702321     2.819092   \n",
      "3     1.206093     1.324558      0.108235      0.035608     1.065871   \n",
      "4     6.509608    16.608572      0.108235      0.035608     1.065871   \n",
      "\n",
      "   TotalBath-3  KitchenQual-2  KitchenQual-3  GarageScore-2  GarageScore-3  \n",
      "0    -0.017739       0.591118       0.454477       0.001635       0.000066  \n",
      "1    -0.017739       5.355100      12.392285       1.168410       1.262970  \n",
      "2     4.733298       5.355100      12.392285       2.476841       3.898049  \n",
      "3     1.100416       0.591118       0.454477       0.216081       0.100444  \n",
      "4     1.100416       5.355100      12.392285       0.171931       0.071290  \n",
      "\n",
      "[5 rows x 309 columns]\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# default columns given\n",
    "cols = [\"OverallQual-s2\", \"OverallQual-s3\", \"OverallQual-Sq\", \"AllSF-2\", \"AllSF-3\", \"AllSF-Sq\",\n",
    "       \"AllFlrsSF-2\", \"AllFlrsSF-3\", \"AllFlrsSF-Sq\", \"GrLivArea-2\", \"GrLivArea-3\", \"GrLivArea-Sq\", \n",
    "       \"SimplOverallQual-s2\", \"SimplOverallQual-s3\", \"SimplOverallQual-Sq\", \n",
    "       \"ExterQual-2\", \"ExterQual-3\", \"ExterQual-Sq\", \"GarageCars-2\", \"GarageCars-3\", \"GarageCars-Sq\",\n",
    "       \"TotalBath-2\", \"TotalBath-3\", \"TotalBath-Sq\", \"KitchenQual-2\", \"KitchenQual-3\", \"KitchenQual-Sq\",\n",
    "       \"GarageScore-2\", \"GarageScore-3\", \"GarageScore-Sq\"]\n",
    "\n",
    "train_path = '../data/Train.csv'\n",
    "test_path = '../data/Test.csv'\n",
    "\n",
    "# load datasets\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "# split into features and target\n",
    "X_train = train.iloc[:,:289]\n",
    "y_train = train.iloc[:,289]\n",
    "\n",
    "X_test = test.iloc[:,:289]\n",
    "y_test = test.iloc[:,289]\n",
    "\n",
    "# take square and cubic power for cols \n",
    "\n",
    "## train part\n",
    "X_train[\"OverallQual-s2\"] = X_train[\"OverallQual\"] ** 2\n",
    "X_train[\"OverallQual-s3\"] = X_train[\"OverallQual\"] ** 3\n",
    "X_train[\"AllSF-2\"] = X_train[\"AllSF\"] ** 2\n",
    "X_train[\"AllSF-3\"] = X_train[\"AllSF\"] ** 3\n",
    "X_train[\"AllFlrsSF-2\"] = X_train[\"AllFlrsSF\"] ** 2\n",
    "X_train[\"AllFlrsSF-3\"] = X_train[\"AllFlrsSF\"] ** 3\n",
    "X_train[\"GrLivArea-2\"] = X_train[\"GrLivArea\"] ** 2\n",
    "X_train[\"GrLivArea-3\"] = X_train[\"GrLivArea\"] ** 3\n",
    "X_train[\"SimplOverallQual-s2\"] = X_train[\"SimplOverallQual\"] ** 2\n",
    "X_train[\"SimplOverallQual-s3\"] = X_train[\"SimplOverallQual\"] ** 3\n",
    "X_train[\"ExterQual-2\"] = X_train[\"ExterQual\"] ** 2\n",
    "X_train[\"ExterQual-3\"] = X_train[\"ExterQual\"] ** 3\n",
    "X_train[\"GarageCars-2\"] = X_train[\"GarageCars\"] ** 2\n",
    "X_train[\"GarageCars-3\"] = X_train[\"GarageCars\"] ** 3\n",
    "X_train[\"TotalBath-2\"] = X_train[\"TotalBath\"] ** 2\n",
    "X_train[\"TotalBath-3\"] = X_train[\"TotalBath\"] ** 3\n",
    "X_train[\"KitchenQual-2\"] = X_train[\"KitchenQual\"] ** 2\n",
    "X_train[\"KitchenQual-3\"] = X_train[\"KitchenQual\"] ** 3\n",
    "\n",
    "## test part\n",
    "X_test[\"OverallQual-s2\"] = X_test[\"OverallQual\"] ** 2\n",
    "X_test[\"OverallQual-s3\"] = X_test[\"OverallQual\"] ** 3\n",
    "X_test[\"AllSF-2\"] = X_test[\"AllSF\"] ** 2\n",
    "X_test[\"AllSF-3\"] = X_test[\"AllSF\"] ** 3\n",
    "X_test[\"AllFlrsSF-2\"] = X_test[\"AllFlrsSF\"] ** 2\n",
    "X_test[\"AllFlrsSF-3\"] = X_test[\"AllFlrsSF\"] ** 3\n",
    "X_test[\"GrLivArea-2\"] = X_test[\"GrLivArea\"] ** 2\n",
    "X_test[\"GrLivArea-3\"] = X_test[\"GrLivArea\"] ** 3\n",
    "X_test[\"SimplOverallQual-s2\"] = X_test[\"SimplOverallQual\"] ** 2\n",
    "X_test[\"SimplOverallQual-s3\"] = X_test[\"SimplOverallQual\"] ** 3\n",
    "X_test[\"ExterQual-2\"] = X_test[\"ExterQual\"] ** 2\n",
    "X_test[\"ExterQual-3\"] = X_test[\"ExterQual\"] ** 3\n",
    "X_test[\"GarageCars-2\"] = X_test[\"GarageCars\"] ** 2\n",
    "X_test[\"GarageCars-3\"] = X_test[\"GarageCars\"] ** 3\n",
    "X_test[\"TotalBath-2\"] = X_test[\"TotalBath\"] ** 2\n",
    "X_test[\"TotalBath-3\"] = X_test[\"TotalBath\"] ** 3\n",
    "X_test[\"KitchenQual-2\"] = X_test[\"KitchenQual\"] ** 2\n",
    "X_test[\"KitchenQual-3\"] = X_test[\"KitchenQual\"] ** 3\n",
    "\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# Add square and cubic powers of 'GarageScore' to train and test\n",
    "X_train[\"GarageScore-2\"] = X_train[\"GarageScore\"] ** 2\n",
    "X_train[\"GarageScore-3\"] = X_train[\"GarageScore\"] ** 3\n",
    "\n",
    "X_test[\"GarageScore-2\"] = X_test[\"GarageScore\"] ** 2\n",
    "X_test[\"GarageScore-3\"] = X_test[\"GarageScore\"] ** 3\n",
    "\n",
    "# logarithmic transformation of target\n",
    "y_train = np.log1p(y_train)\n",
    "y_test = np.log1p(y_test)\n",
    "\n",
    "# display first five rows of train and test features\n",
    "print(X_train.head())\n",
    "print(X_test.head())\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- To add a new column `col_sq` which is the square of another column `col` of a dataframe `df` use `df[col_sq] = df[col] ** 2`. Similarly use 3 to generate cubic power\n",
    "- To transform `y_train` use `y_train = np.log1p(y_train)`. Repeat it for `y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "\n",
    "- Shape of `X_train` is `(1019, 309)`\n",
    "- Shape of `X_test` is `(437, 309)`\n",
    "- First value of `y_train` is `int(y_train[0] )== 12`\n",
    "- First value of `y_test` is `int(y_test[0]) == 12`\n",
    "- New column creations in `X_train` and `X_test` `\"GarageScore-2\", \"GarageScore-3\"` as `\"GarageScore-2\" in X_train.columns and \"GarageScore-3\" in X_train.columns` and `\"GarageScore-2\" in X_test.columns and \"GarageScore-3\" in X_test.columns`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bias-variance trade-off\n",
    "\n",
    "***\n",
    "\n",
    "By now, you already have a brief idea about predictive models; you preprocess the data (clean, remove outliers, skewness etc), fit a model and make prediction on it. Then you will calculate the error metric and try to find the best model that minimizes this error. This error is made up of three parts: \n",
    "- **Error due to squared bias**\n",
    "- **Error due to variance**\n",
    "- **Irreducible error**\n",
    "\n",
    "Mathematically,\n",
    "\n",
    "$Error(x) = {Bias}^2 + Variance + Irreducible Error$\n",
    "\n",
    "Irreducible error is also known as noise, and it can't be reduced by your choice in algorithm. It typically comes from inherent randomness, a misframed problem, or an incomplete feature set. So, we will discuss what is bias and variance and also the trade-off required in order to find a good model.\n",
    "\n",
    "**Error due to squared bias:** Simply put bias is the difference between your model's expected predictions and the true values. Expected predictions mean that you are averaging the predictions of the model (if you repeat the entire model building process on new random data multiple times). Due to the inherent randomness in the data there is bound to be a range for predictions. Bias measures how far off are the predictions from the true values. Bias error arises due to incorrect assumptions in our learning algorithm which makes it hard to learn true relationships between independent and dependent variables.\n",
    "\n",
    "**A low bias model is one that can be highly flexible and has the capacity to fit a variety of different shapes and patterns. A high bias model would be unable to estimate values close to their true values.**  Models with high bias always leads to high error on training and test data.\n",
    "\n",
    "<img src='../images/bias.png'>\n",
    "\n",
    "In the image above no longer how many more data points we add, we simply won't be able to fit a straight line because it is unable to capture non-linear trends. In other words we say that the model is **underfitting** the data.\n",
    "\n",
    "\n",
    "**Error due to variance:** Variance is the degree of fluctuation of a data point for different model predictions (assuming we repeat entire model model building process on new random data multiple times). Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn’t seen before. As a result, such models perform very well on training data but has high error rates on test data.\n",
    "\n",
    "<img src='../images/variance.png'>\n",
    "\n",
    "In the image above the model is capturing almost every data point and learns too much; when we test it on unseen data it will not generalize well and produces a high error. This phenomenon is also called **overfitting**. \n",
    "\n",
    "**Linear models in general have high bias because of its inability to capture non-linear patterns.**\n",
    "\n",
    "### Graphical representation of bias-variance\n",
    "\n",
    "<img src='../images/bvgraph.jpg'>\n",
    "\n",
    "The above image is a graphical visualization of bias and variance using a bulls-eye diagram. Here, the center of the target is a model that perfectly predicts the correct values. As we move away from the bulls-eye, our predictions get worse and worse. Imagine we can repeat our entire model building process to get a number of separate hits on the target. Each hit represents an individual realization of our model, given the chance variability in the training data we gather. Sometimes we will get a good distribution of training data so we predict very well and we are close to the bulls-eye, while sometimes our training data might be full of outliers or non-standard values resulting in poorer predictions. These different realizations result in a scatter of hits on the target.\n",
    "\n",
    "We can plot four different cases representing combinations of both high and low bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Root Mean Squared Error \n",
    "\n",
    "In this task you will calculate the RMSE for the dataset using linear regression \n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Instantiate a linear model `model` using `LinearRegression()` which has already been imported and fit it on training features `X_train` and target `y_train`\n",
    "- Make prediction on the test features `X_test` and save them as `preds`\n",
    "- Calculate the mean squared error, save it as `rmse` and print it out. Make sure to **square root the mean squared error** to find the RMSE using `np.sqrt(mean_squared_error(predictions, actual))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12100920536629416\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# new_cols = [\"OverallQual-s2\", \"OverallQual-s3\", \"AllSF-2\", \"AllSF-3\", \"AllFlrsSF-2\", \"AllFlrsSF-3\",\n",
    "#            \"GrLivArea-2\", \"GrLivArea-3\", \"SimplOverallQual-s2\", \"SimplOverallQual-s3\",\n",
    "#            \"ExterQual-2\", \"ExterQual-3\", \"GarageCars-2\", \"GarageCars-3\", \"TotalBath-2\", \"TotalBath-3\",\n",
    "#            \"KitchenQual-2\", \"KitchenQual-3\", \"GarageScore-2\", \"GarageScore-3\" ]\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# instantiate and fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions and calculate rmse\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(preds, y_test))\n",
    "print(rmse)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate `model` using `model = LinearRegression()`\n",
    "- Use `.fit()` method of `model` on `X_train` and `y_train`\n",
    "- Use `.predict()` method of `model` on `X_test` and save it as `preds`\n",
    "- Calculate `rmse` as `rmse = np.sqrt(mean_squared_error(preds, y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable decalaration for `model`, `preds` and `rmse`\n",
    "- First value of `preds` is `int(preds[0]) == 12`\n",
    "- Length of `preds` is `len(preds) == 437`\n",
    "- RMSE value is `round(rmse, 2) == 0.12`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model complexity\n",
    "\n",
    "***\n",
    "\n",
    "**Definition:** Model complexity can be defined as a function of number of free parameters; the more free parameters a model has, the more complex the model is. In a dataset the free parameters are the independent variables (features) and so model complexity increases with increasing number of features and vice-versa.\n",
    "\n",
    "\n",
    "**Relationship between model complexity and bias-variance**\n",
    "\n",
    "Understand it this way: the more number of features you have, more the model will remember the patterns and hence more will be the variance. On the other hand if you decrease the number of features at hand you are reducing the memory power of the model (you are reducing variance) and if you do it too much it may ultimately lead to a generalization where the variance is very low but the bias is very high. The bias increases because you are having too many restrictions by reducing the number of features. So, while we try to reduce the variance bias increases and vice-versa. There is a trade-off between the two which is shown by the graph below:\n",
    "\n",
    "<img src='../images/model_complexity.png'>\n",
    "\n",
    "The above image captures the total error on the test data. Observe that with increasing model complexity bias decreases while variance decreases. At the same time the total error continues to go down until a point and from there onwards it shoots upwards. This point also called sometimes as the *sweet spot* is the condition we try to achieve by balancing the bias and variance. \n",
    "\n",
    "**Footnote**\n",
    "\n",
    "- **Overfitting:** too much reliance on the training data\n",
    "- **Underfitting**: a failure to learn the relationships in the training data\n",
    "- **High Variance:** model changes significantly based on training data\n",
    "- **High Bias:** assumptions about model lead to ignoring training data\n",
    "- **Overfitting** and **underfitting** cause poor generalization on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe underfitting\n",
    "\n",
    "In this task you will select only the first $100$ features and calculate the test error to observe underfitting\n",
    "\n",
    "### Instructions\n",
    "- Create new training features set and test features set `new_X_train` and `new_X_test` consisting of all the instances for `X_train` and `X_test` respectively but has only the first $100$ features\n",
    "- Instantiate a linear model again `model_2` and fit it on `new_X_train` and `y_train`\n",
    "- Make predictions on the test set `new_X_test` and save it as `pred_2`\n",
    "- Calculate RMSE `rmse_2` in the same manner that you did in the previous task. Print it out to see the error and observe underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6712418158.670321\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "# instantiate new model\n",
    "model_2 = LinearRegression()\n",
    "\n",
    "# train and test sets with 100 features\n",
    "new_X_train = X_train.iloc[:,:100]\n",
    "new_X_test = X_test.iloc[:,:100]\n",
    "\n",
    "# fit and predict\n",
    "model_2.fit(new_X_train, y_train)\n",
    "pred_2 = model_2.predict(new_X_test)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse_2 = np.sqrt(mean_squared_error(pred_2, y_test))\n",
    "print(rmse_2)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate `model_2` as `model_2 = LinearRegression()`\n",
    "- Select first 100 columns from `X_train` as `new_X_train = X_train.iloc[:,:100]`. Similarly repeat it for `X_test` and save it as `new_X_test`\n",
    "- Use `.fit()` method of `model_2` on `new_X_train` and `y_train`\n",
    "- Calculate `pred_2` using `.predict()` method of `model_2` on `new_X_test`\n",
    "- Calculate `rmse_2` as `rmse_2 = np.sqrt(mean_squared_error(pred_2, y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `model_2`, `new_X_train`, `new_X_test`, `pred_2`, `rmse_2`\n",
    "- Shape of `new_X_train`: `new_X_train.shape == (1019, 100)`\n",
    "- Shape of `new_X_test`: `new_X_test.shape == (437, 100)`\n",
    "- First value of `pred`: `int(pred_2[0]) == 12`\n",
    "- Value of `rmse_2`: `round(rmse_2, 2) == 6712418158.67`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe how the RMSE went up as compared with the original model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Effect of training set size\n",
    "\n",
    "***\n",
    "\n",
    "As already covered in the previous topic, increase of bias leads to a decrease in variance and vice-versa. you also learnt about the *sweet spot* which our model should always try to achieve so that it has a good amount of generalization power on unseen data. This relationship between bias and variance is thus called the Bias-variance trade-off. \n",
    "\n",
    "The ideal model should strive to avoid high bias (underfitting) and high variance (overfitting) and achieve a good balance as shown in the diagram below:\n",
    "\n",
    "<img src='../images/balance.png' width=600>\n",
    "\n",
    "Now lets observe the behaviour of two models; one having high bias and the other with high variance on similar model complexity:\n",
    "\n",
    "1. **Model with high bias:** A model with high bias will have a high training set error because the average value of predictions are far off the true values. **Now, if we increase the size of the training set the training error will not decrease too much due to incorrect assumptions of the model**. As a result, it will fare poorly during the prediction phase as well. **And obviously the test set error will be bad since the model hasn't learnt properly. It will decrease initially until a point where the decrease becomes almost non-existent.**\n",
    "\n",
    "<img src='../images/lc_bias.png' width=500>\n",
    "\n",
    "2. **Model with high variance:** Now a learning algorithm high variance will have a low training set error because it learns almost everything from data points. **As we increase the training set size it will try to incorporate learnings from the new data points and find some general setting due to which training set error increases slightly**. The new learnings improves the generalization capability of the algorithm due to which the **test set error decreases**. \n",
    "\n",
    "<img src='../images/lc_variance.png' width=500>\n",
    "\n",
    "To summarize our discussions so far: Adding more training instances to a high bias model won't help too much but can help in case of a high variance model.\n",
    "\n",
    "<img src='../images/training_set_size.png' width=600>\n",
    "\n",
    "**Motivation to use Regularization**\n",
    "\n",
    "Regularization is the method by which you can address the problem of overfitting. To reduce overfitting you can either try reducing the model complexity or increasing the training set size. Regularization achieves exactly that by reducing the model complexity and you will see how in the next chapter! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: What is Regularization?\n",
    "\n",
    "### Description: In this chapter you will learn what regularization is and how it addresses the issue of overfitting along with its different types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Introduction\n",
    "\n",
    "***\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "Regularization is a technique used to prevent overfitting in datasets. It does so by reducing the magnitude of the coefficients of the attributes. More is the magnitude of the co-efficient, more is its predictive power. But a very high magnitude of co-efficent/s mean that the learning algorithm has modeled the pattern as well as the noise. This noise can be eliminated by regularization.\n",
    "\n",
    "\n",
    "**How does regularization reduce noise?**\n",
    "\n",
    "As written above, regularization reduces noise. But how? Simply by penalizing the co-efficients according to some function along with the loss function. Lets see how.\n",
    "\n",
    "The cost function for linear regression is:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x_i)-y_i)^2$$\n",
    "\n",
    "You penalize your loss function by adding a multiple of the norm of your weights/co-efficients vector  $w$  (it is the vector of the learned parameters in your linear regression). You get the following equation:  $$J(\\theta) = L(x,y)+λN(\\theta_i)$$ where $L(x,y)$ is the cost function and $N(w_i)$ is the norm of the coefficients and $\\lambda$ is a constant called the regularization parameter. \n",
    "\n",
    "\n",
    "**Intuition behind regularization**\n",
    "\n",
    "More is the cost function, the more it is penalized i.e. more is the magnitude of the coefficients, more the function penalized. In this way it reduces the importance given to the predictor variables which results in decreased variance. This makes sure that the algorithm doesn't learn too much from the training data and generalizes well on unseen data. \n",
    "\n",
    "Another factor that we have not yet talked about is that the computational resources used up is directly proportional to the number of features. If it becomes too huge, then calculation could become cumbersome and regularization at that point can be an effective method to counter the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Types of Regularization\n",
    "\n",
    "***\n",
    "\n",
    "Now that you know what regularization is, lets proceed to understanding the variants of regularization. There are three main types and they all vary in the $N(\\theta)$ function:\n",
    "1. **Lasso (L1):** It stands for *Least Absolute Shrinkage and Selection Operator* and adds **absolute value of magnitude of coefficient** as penalty term to the loss function. Mathematically, the new regularized cost function becomes:  $$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x_i)-y_i)^2 + \\lambda\\sum_{i=1}^{n}|\\theta_i|$$ \n",
    "\n",
    "2. **Ridge (L2):** Ridge regression adds **squared magnitude of coefficient** as penalty term to the loss function. The new cost function becomes: \n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x_i)-y_i)^2 + \\lambda\\sum_{i=1}^{n}{\\theta_i}^2$$ \n",
    "\n",
    "\n",
    "3. **Elastic Net :** It combines both L1 and L2 to overcome the individual challenges and penalizes **both absolute and squared magnitude of coefficient.** The cost function for Elastic net is:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x_i)-y_i)^2 + \\lambda_1\\sum_{i=1}^{n}{\\theta_i}^2 + \\lambda_2\\sum_{i=1}^{n}|\\theta_i|$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Lasso (L1) regularization\n",
    "\n",
    "***\n",
    "\n",
    "So, Lasso regression penalizes the absolute magnitude of coefficient in the loss function or mathematically\n",
    " $$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x_i)-y_i)^2 + \\lambda\\sum_{i=1}^{n}|\\theta_i|$$\n",
    "\n",
    "**Variable selection property of Lasso**\n",
    "\n",
    "The two key words in its full form *Least Absolute Shrinkage and Selection Operator* are **Absolute** and **Selection**. Here, **absolute** means penalizing the magnitude of the coefficients of predictors and **selection** refers to the ability of L1 method to reduce some of the coefficients to $0$. In this way the number of features get reduced and we now have only a subset of features. \n",
    "\n",
    "This property of selection is particularly important if you have a large number of features at disposal. Multicollinearity and non-linear trends can exist and its not feasible to check for each and every feature. Lasso provides a way around this conundrum by reducing redundant features and keeping only those features which are relevant. In case of correlated features it arbitrarily selects any one feature among the highly correlated ones and reduces the coefficients of the rest to zero. Also, the chosen variable changes randomly with change in model parameters.\n",
    "\n",
    "\n",
    "\n",
    "**Role of regularization parameter ($\\lambda$)**\n",
    "\n",
    "Here, $\\lambda$ (lambda) provides a trade-off between balancing the cost function and magnitude of coefficients. \n",
    "-  Very low values of $\\lambda$ low might not do anything.\n",
    "- $\\lambda = 0$: Same coefficients as simple linear regression and the same cost function\n",
    "- $\\lambda = ∞$: All coefficients zero as there will be high penalty causing underfitting \n",
    "- $0 < \\lambda < ∞$: coefficients between $0$ and that of simple linear regression including $0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does lasso do better?\n",
    "\n",
    "In this task you will be using Lasso Regression (L1 norm) and calculate the RMSE on the test data\n",
    "\n",
    "### Instructions\n",
    "- Instantiate a Lasso model `lasso` using `Lasso()` which has already been imported and fit it on the training features `X_train` and training target `y_train`\n",
    "- Make predictions on the test features `X_test` and save it as `lasso_pred`\n",
    "- Calculate the RMSE `lasso_rmse` and print it out\n",
    "- Check out how many feature coefficients are zero using `lasso.coef_ == 0` and save it as `zero_features`. Print it out to check its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38395194472872235\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# instantiate lasso model\n",
    "lasso = Lasso()\n",
    "\n",
    "# fit and predict\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "# calculate RMSE\n",
    "lasso_rmse = np.sqrt(mean_squared_error(lasso_pred, y_test))\n",
    "print(lasso_rmse)\n",
    "\n",
    "# check how many feature coefficients are zero\n",
    "zero_features = sum(lasso.coef_ == 0)\n",
    "print(zero_features)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate Lasso model with `lasso = Lasso()`\n",
    "- Use `.fit()` method of `lasso` on `X_train` and `y_train`\n",
    "- Calculate `lasso_pred` using `.predict()` method of `lasso` on `X_test`\n",
    "- Calculate `lasso_rmse` as `lasso_rmse = np.sqrt(mean_squared_error(lasso_pred, y_test))`\n",
    "- Calculate `zero_features` as `zero_features = sum(lasso.coef_ == 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `lasso`, `lasso_pred`, `lasso_rmse` and `zero_features`\n",
    "- First value of `lasso_pred`: `int(lasso_pred) == 12`\n",
    "- Length of the array `lasso_pred`: `len(lasso_pred) == 437`\n",
    "- value of `lasso_rmse`: `round(lasso_rmse,2) == 0.38`\n",
    "- Value of `zero_features`: `zero_features == 308`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Ridge (L2) regularization\n",
    "\n",
    "***\n",
    "\n",
    "Ridge penalizes the squared magnitude of coefficient in the cost function. Mathematically,\n",
    "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x_i)-y_i)^2 + \\lambda\\sum_{i=1}^{n}{\\theta_i}^2$$ \n",
    "\n",
    "But unlike Lasso it doesn't reduce the coefficients to $0$. Rather it only performs shrinkage of all the coefficients. Note that **coefficients that are further from zero pull stronger towards zero**. This makes it more stable around zero because the regularization changes gradually around zero. \n",
    "\n",
    "Since the coefficients are squared in the penalty expression, it has a different effect from the L1 norm, namely it forces the coefficient values to be spread out more equally. For correlated features, it means that they tend to get similar coefficients. \n",
    "\n",
    "**Role of regularization parameter ($\\lambda$)**\n",
    "\n",
    "- $\\lambda = 0$: The objective becomes same as simple linear regression and we get the same coefficients as simple linear regression.\n",
    "- $\\lambda = ∞$: The coefficients will be zero. Why? Because of infinite weightage on square of coefficients, anything less than zero will make the objective infinite.\n",
    "- $0 < \\lambda < ∞$: The coefficients will be somewhere between $0$ and ones for simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Ridge do better?\n",
    "\n",
    "In this task you will be using Ridge Regression (L2 norm) and calculate the RMSE on the test data\n",
    "\n",
    "### Instructions\n",
    "- Instantiate a Ridge model `ridge` using `Ridge()` which has already been imported and fit it on the training features `X_train` and training target `y_train`\n",
    "- Make predictions on the test features `X_test` and save it as `ridge_pred`\n",
    "- Calculate the RMSE, save it as `ridge_rmse` and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38395194472872235\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# instantiate lasso model\n",
    "ridge = Ridge()\n",
    "\n",
    "# fit and predict\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = lasso.predict(X_test)\n",
    "\n",
    "# calculate RMSE\n",
    "ridge_rmse = np.sqrt(mean_squared_error(ridge_pred, y_test))\n",
    "print(ridge_rmse)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate Ridge model as `ridge = Ridge()`\n",
    "- Use `.fit()` method of `ridge` on `X_train` and `y_train`\n",
    "- Calculate `ridge_pred` using `.predict()` method on `X_test`\n",
    "- Calculate `ridge_rmse` as `ridge_rmse = np.sqrt(mean_squared_error(ridge_pred, y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `ridge`, `ridge_pred` and `ridge_rmse`\n",
    "- First value of `ridge_pred`: `int(ridge_pred[0]) == 12`\n",
    "- Length of `ridge_pred`: `len(ridge_pred) == 437`\n",
    "- Value of `ridge_rmse`: `round(ridge_rmse, 2) == 0.38`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 L1 vs L2 regularization\n",
    "\n",
    "***\n",
    "\n",
    "Lets compare L1 and L2 based on some important characteristics:\n",
    "\n",
    "\n",
    "- **Computational difficulty**\n",
    "\n",
    "Ridge has a closed-form solution because it's a square of something but Lasso does not because it is a non-differentiable piecewise function, as it involves an absolute value. For this reason, Lasso is computationally more expensive, as we can't solve it in terms of matrix math, and mostly rely on approximations (in the lasso case, coordinate descent).\n",
    "\n",
    "\n",
    "- **Sparsity**\n",
    "\n",
    "Sparsity means that only very few entries in a matrix (or vector) is non-zero. Lasso has the property of producing many coefficients with zero values or very small values with few large coefficients and so it often tends to have a great sparsity as compared to Ridge.\n",
    "\n",
    "\n",
    "- **Solution numeracy**\n",
    "\n",
    "As L2 is the Euclidean distance, there is always one right answer as to how to get between two points. While L1 is manhattan distance (taxicab distance), there are as many solutions to getting between two points as there are ways of driving between two points in Manhattan! This is best illustrated by the image below:\n",
    "\n",
    "<img src='../images/l1vsl2.svg'>\n",
    "\n",
    "The **green** line represents L2 distance while the **blue, yellow** and **red** represents the L1 distance.\n",
    "\n",
    "\n",
    "- **Built-in feature selection** \n",
    "\n",
    "Lasso has the ability to perform feature selection by eliminating redundant features but Ridge does not. This is actually a result of the L1-norm, which tends to produces sparse coefficient. Suppose the model have 100 coefficients but only 10 of them have non-zero coefficients, this is effectively saying that “the other 90 predictors are useless in predicting the target values”. L2-norm produces non-sparse coefficients, so does not have this property. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Cross-validation and Hyperparameter tuning\n",
    "\n",
    "### Description: In this chapter you will learn how to validate your models and find the best possible set/s of hyperparameters for your learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 What is the difference between parameter and hyperparameter?\n",
    "\n",
    "***\n",
    "\n",
    "Before understanding about cross-validation and hyperparameter tuning and why do you even need to do it in the first place, lets understand what is a hyperparameter and how does it differ from a parameter.\n",
    "\n",
    "\n",
    "**What is a parameter?**\n",
    "\n",
    "Imagine you have built a linear regression model which has feature coefficients $\\theta_1, \\theta_2, ...., \\theta_n$. This model assumes that the relationship between predictors and target variable is linear. The variable $\\theta_i$ is a weight vector that represents the normal vector for the line; it specifies the slope of the line. This is known as a model parameter, which is being learnt during the training phase. **So, any property of the training data that is being learnt by the learning algorithm in the training phase is a parameter.** In our example, the coefficients are the parameters as they are found after minimizing the total training error.\n",
    "\n",
    "\n",
    "**What is a hyperparameter?**\n",
    "\n",
    "There is another set of parameters known as hyperparameters, whose values must be specified outside of the training procedure. Remember the learning rate in gradient descent! The value of learning rate had to be specified before we estimate the value of  $\\theta$  (which is a parameter). While linear regression itself does not have any hyperparameters, variants of linear regression like ridge regression and lasso both add a regularization term to linear regression; the penalizing coefficient for the regularization term is the hyperparameter. Hyperparameters can be thought of as knobs by which we can control the performance of our learning algorithm. **Remember that they are specified externally and cannot be learnt by the model.**\n",
    "\n",
    "\n",
    "**Key differences**\n",
    "\n",
    "- Parameters are estimated by the learning algorithm during training phase whereas hyperparameters are not.\n",
    "- Hyperparameter values can be manually provided while parameter values cannot be provided\n",
    "- Number of parameters can sometimes be impossible to determine (in case of non-parametric models) but number of hyperparameters are fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Why do we need them?\n",
    "\n",
    "***\n",
    "\n",
    "Lets say you have built two different models **A** and **B**. The next step logically should be to validate them on unseen data in order to determine their stability. You need to make sure that they generalize well on unseen data and is capturing only relevant patterns and ignoring the noise. At this point you will face two key issues:\n",
    "- How to select the best model?\n",
    "- Once the model is selected, how to find its best set of hyperparameters?\n",
    "\n",
    "\n",
    "**Naive approach**\n",
    "\n",
    "You might be tempted to use the entire training data to train your learning algorithm and cross your fingers that it performs well on unseen data and then find the right setting of hyperparameters. Well this is a naive approach to do because it may lead to **overfitting**.\n",
    "\n",
    "\n",
    "**How to avoid it?**\n",
    "\n",
    "<img src='../images/model_selection.png' width=600>\n",
    "\n",
    "In the above figure the historical data (training data) is divided into two halves; namely training and validation data. Note that here hyperparameter tuning is illustrated as a **meta** process that controls the training process. In the coming topics you will learn how to get the best set of hyperparameters. Then, the model training process receives training data and produces a model, which is evaluated on validation data. The results from validation are passed back to the hyperparameter tuner, which tweaks some knobs and trains the model again.\n",
    "\n",
    "In this way you can ensure that your unseen data which is generally assumed to be independent from training data gives us an estimate of the generalization error and take a call on the learning ability of the algorithm.\n",
    "\n",
    "But how do you select the validation set? Proceed to the next topic to learn how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Holdout Method\n",
    "\n",
    "Lets discuss the **holdout** validation strategy which will help you to chose the best model.\n",
    "\n",
    "<img src='../images/holdout.png' width=400>\n",
    "\n",
    "The most simple strategy involves removing a part of the training data and using it to get predictions from the model trained on rest of the data. Then the error will tell how the model is doing on unseen data which is the validation set in this scenario. It is also known as the holdout method.\n",
    "\n",
    "This is because it is not certain which data points will end up in the validation set and the result might be entirely different for different sets. If we happen to get an **unfortunate split**, then you may end up rejecting that model and chosing a poor one although the former one has a better generalization power. Another drawback is that with sparse datasets, you may not even have the flexibility to set aside a portion of the training data for validation purposes. Its only advantage is that it is computationally much cheaper that other validation strategies.\n",
    "\n",
    "\n",
    "**You can overcome the drawbacks of holdout method by using cross-validation strategies.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will you chose Lasso or Ridge with the Holdout method?\n",
    "\n",
    "In this task you will validate both lasso and ridge models by using a holdout set from the training features and target and finally calculate the RMSE on the test data\n",
    "\n",
    "### Instructions\n",
    "- The training and hold-out sets have been made for you. Training features and targets are `train_feat` and `train_tar` respectively while holdout features and targets are `test_feat` and `test_tar` respectively\n",
    "- Initiate a lasso model `l1` and a ridge regression model `l2` and fit them on the the training data i.e. `train_feat` and `train_tar`\n",
    "- Make predictions for both `l1` and `l2` using `.predict()` on `test_feat` and save them as `pred_l1` (for `l1`) and `pred_l2` (for `l2`)\n",
    "- Then check both their performances using RMSE as metric on the validation data using `mean_squared_error()` on the predictions and holdout target `test_tar` and save them as `rmse_l1` (for `l1`) and `rmse_l2` (for `l2`)\n",
    "- Pick the model which gave the best performance on validation data and use it to make prediction for test data using `selected_model = l1 if rmse_l1 < rmse_l2 else l2`\n",
    "- Now make predictions on the test features i.e. `X_test` using `.predict()` on it and save it as `selected_model_pred`\n",
    "- Calculate RMSE on the test target `y_test` using `mean_squared_error()` and save it as `rmse_selected_model_pred` and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "0.12958504096147183\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into training and validation\n",
    "train_feat, test_feat, train_tar, test_tar = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# initiate lasso and ridge\n",
    "l1 = Lasso()\n",
    "l2 = Ridge()\n",
    "\n",
    "# fit on training\n",
    "l1.fit(train_feat, train_tar)\n",
    "l2.fit(train_feat, train_tar)\n",
    "\n",
    "# make predictions and calculate RMSE on validation data\n",
    "pred_l1 = l1.predict(test_feat)\n",
    "pred_l2 = l2.predict(test_feat)\n",
    "\n",
    "rmse_l1 = np.sqrt(mean_squared_error(pred_l1, test_tar))\n",
    "rmse_l2 = np.sqrt(mean_squared_error(pred_l2, test_tar))\n",
    "\n",
    "# select best model\n",
    "selected_model = l1 if rmse_l1 < rmse_l2 else l2\n",
    "print(selected_model)\n",
    "\n",
    "# make prediction on test data and calculate RMSE\n",
    "selected_model_pred = selected_model.predict(X_test)\n",
    "rmse_selected_model_pred = np.sqrt(mean_squared_error(selected_model_pred, y_test))\n",
    "print(rmse_selected_model_pred)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate Lasso and Ridge as `l1 = Lasso()` and `l2 = Ridge()`\n",
    "- Use `.fit()` method of `l1` and `l2` on `train_feat` and `train_tar`\n",
    "- Calculate `pred_l1` and `pred_l2` using `.predict()` on `test_feat`\n",
    "- Calculate `rmse_l1` and `rmse_l2` using `np.sqrt(mean_squared_error(preds, test_tar))`\n",
    "- To find `selected_model` as `selected_model = l1 if rmse_l1 < rmse_l2 else l2`\n",
    "- Calculate `selected_model_pred` as `selected_model_pred = selected_model.predict(X_test)`\n",
    "- Calculate `rmse_selected_model_pred` as `rmse_selected_model_pred = np.sqrt(mean_squared_error(selected_model_pred, y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `l1`, `l2`, `pred_l1`, `pred_l2`, `rmse_l1`, `rmse_l2`, `selected_model`, `selected_model_pred`, `rmse_selected_model_pred`\n",
    "- Length of `pred_l1`: `len(pred_l1) == 255`\n",
    "- Length of `pred_l2`: `len(pred_l2) == 255`\n",
    "- First value of `pred_l1`: `int(pred_l1[0]) == 12`\n",
    "- First value of `pred_l2`: `int(pred_l2[0]) == 11`\n",
    "- RMSE: `round(rmse_l1, 2) == 0.4`\n",
    "- RMSE: `round(rmse_l2, 2) == 0.14`\n",
    "- Selected model predictions: `int(selected_model_pred[0]) == 12`\n",
    "- RMSE of selected model predictions: `round(rmse_selected_model_pred, 2) == 0.13`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Cross-validation strategies\n",
    "\n",
    "***\n",
    "\n",
    "Cross-validation is simply a way of generating training and validation sets. There is never enough data to train your model, removing a part of it for validation poses a problem of underfitting while selecting all data for training can cause overfitting. Therefore, you require an appropriate method that provides ample data for training the model and also leaves ample data for validation. **Cross validation does exactly that**.\n",
    "\n",
    "\n",
    "<img src='../images/crossval.jpg' width=400>\n",
    "\n",
    "There are many variants of cross-validation and the most widely used is **K-fold cross-validation**. The image above demonstrates a **K-fold strategy**, where we first divide the training dataset into **K** folds.\n",
    "\n",
    "For a given hyperparameter setting each of the K  folds takes turns being the hold-out validation set; a model is trained on the rest of the **K – 1** folds and measured on the held-out fold. The overall performance is taken to be the average of the performance on all **K** folds. This procedure is then repeated for all of the hyperparameter settings that need to be evaluated.\n",
    "\n",
    "A special variant of K-fold cross-validation is **leave-p-out cross-validation**. This is essentially the same as k-fold cross-validation, where p is equal to the total number of data points in the dataset. If p is equal to $1$, then this method is referred to as **leave one out cross validation**.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use K-Fold cross validation for model selection\n",
    "\n",
    "In this task you will use the K-fold cross validation technique to select the best model between L1 and L2 on $10$ folds of the training data\n",
    "\n",
    "### Instructions\n",
    "- Initialize a lasso model as `L1` and a ridge model as `L2`\n",
    "- Use the `-np.mean(cross_val_score())` to calculate the average of the RMSE's for $10$ folds of training data for **both L1 and L2**. Go through its [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) to better understand its working. For each of the models:\n",
    "     - Take the first argument as the name of the model (`L1`/`L2`) \n",
    "     - Second and third arguments as the training features and training target (`X_train` and `X_test`)\n",
    "     - Use `scoring=scorer` to use RMSE as error metric\n",
    "     - Use `cv=10` to carry out $10$ fold cross validation   \n",
    "- The one out of `L1` and `L2` which gives the lower average RMSE with this strategy will be our model. Do it using `Model = L1 if rmse_l1 else L2`. Print it out to see which model you have chosen\n",
    "- Now select this model `Model` and use it to make predictions on `X_test` and save it as `Pred`\n",
    "- Calculate the RMSE using `mean_squared_error()` on `Pred` and `y_test` and save it as `Error`. Print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15159208908232985 0.016557158015024206\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "0.38395194472872235\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# instantiate L1 and L2\n",
    "L1 = Lasso()\n",
    "L2 = Ridge()\n",
    "\n",
    "# cross validation with L1\n",
    "rmse_L1 = -np.mean(cross_val_score(L1, X_train, y_train, scoring=scorer, cv=10))\n",
    "\n",
    "# cross validation with L2\n",
    "rmse_L2 = -np.mean(cross_val_score(L2, X_train, y_train, scoring=scorer, cv=10))\n",
    "\n",
    "print(rmse_L1, rmse_L2)\n",
    "\n",
    "# select best model\n",
    "Model = L1 if rmse_l1 else L2\n",
    "print(Model)\n",
    "\n",
    "# calculate RMSE on test data\n",
    "Model.fit(X_train, y_train)\n",
    "Pred = Model.predict(X_test)\n",
    "Error = np.sqrt(mean_squared_error(Pred, y_test))\n",
    "print(Error)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `L1`, `L2`, `rmse_L1`, `rmse_L2`, `Model`, `Pred`, `Error`\n",
    "- Value of `rmse_L1`: `round(rmse_L1,2) == 0.15`\n",
    "- Value of `rmse_L2`: `round(rmse_L2, 2) == 0.14`\n",
    "- First value of `Pred`: `int(Pred[0]) == 12`\n",
    "- Value of `Error`: `round(Error, 2) == 0.38`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe how the RMSE went up as compared with the original model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate Lasso and Ridge as `L1 = Lasso()` and `L2 = Ridge()`\n",
    "-  Calculate `rmse_L1` as `rmse_L1 = -np.mean(cross_val_score(L1, X_train, y_train, scoring=scorer, cv=10))`. Similarly calculate `rmse_L2`\n",
    "- Select `Model` as `Model = L1 if rmse_l1 else L2`\n",
    "- Use `.fit()` of `Model` on `X_train` and `y_train`\n",
    "- Calculate `Pred` as `Pred = Model.predict(X_test)`\n",
    "- Calculate `Error` as `Error = np.sqrt(mean_squared_error(Pred, y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Hyperparamter tuning\n",
    "\n",
    "***\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "After model selection comes the part of selecting the best possible set of hyperparamteres. This is the  process of hyperparameter tuning where we find the combination of hyperparameter values for a machine learning model that performs the best on a validation dataset. Hyperparameters can be thought of as model settings which need to be tuned for each problem because the best model hyperparameters for one particular dataset will not be the best across all datasets. \n",
    "\n",
    "\n",
    "**Mechanism of tuning hyperparameters**\n",
    "\n",
    "Lets take an example where you have selected an L1 model and you want to find out the best value of $\\lambda$. You can select the values of $\\lambda$ according to the following ways:\n",
    "\n",
    "- **Grid search:** As the name itself suggests, it evaluates every possible combination of hyperparameters from a grid and picks up the best combination. In our example it means we are selecting a bunch of values for $\\lambda$ i.e. $\\lambda_1$, $\\lambda_2$, $\\lambda_3$, ...., $\\lambda_n$ and evaluate our model on the validation set for each of these values and later return the best $\\lambda$.\n",
    "\n",
    "    Grid search is dead simple to set up but is the most expensive method in terms of total computation time.\n",
    "\n",
    "<img src='../images/grid.jpeg'>\n",
    "\n",
    "- **Random search:** Random search is a slight variation on grid search. Instead of searching over the entire grid, random search only evaluates a random sample of points on the grid. This makes random search a lot cheaper than grid search. With our example of finding the best $\\lambda$, we can simply define a range $[\\lambda_1, \\lambda_2]$ and leave it to random search where it will find randomly select values for $\\lambda$ within this range and return the one with the best performance on validation set. \n",
    "\n",
    "<img src='../images/random.jpeg'>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best model by cross-validation using Grid Search\n",
    "\n",
    "In this task you will select the best model by performing both cross-validation with Grid Search and then calculating the test error on the best model\n",
    "\n",
    "### Instructions\n",
    "- You are given a list of values for regularization parameters for Ridge and Lasso variants as `ridge_lambdas` and `lasso_lambdas` respectively\n",
    "- Instantiate Lasso and Ridge models as `lasso_model` and `ridge_model` respectively\n",
    "- Inside `GridSearchCV()` pass `estimator` as `ridge_model`, `param_grid=dict(alpha=ridge_lambdas)` to do grid search on the Ridge model and save it as `ridge_grid`. Then fit `ridge_grid` on `X_train` and `y_train`\n",
    "- In a similar manner for Lasso, inside `GridSearchCV()` pass `estimator` as `lasso_model`, `param_grid=dict(alpha=alpha_lambdas)` to do grid search and save it as `lasso_grid`. Then fit `lasso_grid` on `X_train` and `y_train`\n",
    "- Make predictions on test features `X_test` for both of these models i.e. `ridge_gird` and `lasso_grid` using `.predict()` and save them as `lasso_pred` and `ridge_pred` for Lasso and Ridge models respectively. (This automatically selects the best parameters based on cross validation)\n",
    "- Then calculate the RMSEs as `lasso_rmse` and `ridge_rmse`\n",
    "- Initialize a variable `best_model` that stores `LASSO` if RMSE for lasso model is lower or else stores `RIDGE`\n",
    "- Print oout `best_model` to see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# regularization parameters for grid search\n",
    "ridge_lambdas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60]\n",
    "lasso_lambdas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1]\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# instantiate lasso and ridge models\n",
    "ridge_model = Ridge()\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# grid search on lasso and ridge\n",
    "ridge_grid = GridSearchCV(estimator=ridge_model, param_grid=dict(alpha=ridge_lambdas))\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "lasso_grid = GridSearchCV(estimator=lasso_model, param_grid=dict(alpha=lasso_lambdas))\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "# make predictions \n",
    "ridge_pred = ridge_grid.predict(X_test)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(ridge_pred, y_test))\n",
    "\n",
    "lasso_pred = lasso_grid.predict(X_test)\n",
    "lasso_rmse = np.sqrt(mean_squared_error(lasso_pred, y_test))\n",
    "\n",
    "# print out which is better\n",
    "best_model = \"LASSO\" if lasso_rmse < ridge_rmse else \"RIDGE\"\n",
    "print(best_model)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "- Variable declaration for `ridge_model`, `lasso_model`, `ridge_grid`, `lasso_grid`, `ridge_pred`, `ridge_rmse`, `lasso_pred`, `lasso_rmse`, `best_model`\n",
    "- value for `lasso_rmse`: `round(lasso_rmse, 2) == 0.11`\n",
    "- Value for `ridge_rmse`: `round(ridge_rmse, 2) == 0.11`\n",
    "- Value for `best_model`: `best_model == \"LASSO\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "- Instantiate `ridge_model` and `lasso_model` using `ridge_model = Ridge()` and `lasso_model = Lasso()`\n",
    "- Grid search on ridge model as `ridge_grid = GridSearchCV(estimator=ridge_model, param_grid=dict(alpha=ridge_lambdas))`. To do it using `lasso_model` just replace `estimator` and `alpha` parameters inside the `GridDearchCV` function with their respective lasso parameters\n",
    "- Use `.fit()` on `X_train` and `y_train` for both `lasso_grid` and `ridge_grid`\n",
    "- Calculate `ridge_pred` as `ridge_pred = ridge_grid.predict(X_test)`. Similarly calculate `lasso_pred`\n",
    "- Calculate `ridge_rmse` as `ridge_rmse = np.sqrt(mean_squared_error(ridge_pred, y_test))`\n",
    "- Find `best_model` as `best_model = \"LASSO\" if lasso_rmse < ridge_rmse else \"RIDGE\"`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
